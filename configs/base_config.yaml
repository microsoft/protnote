---
# Parameters for model training
#TODO: Optimizer can also be a hyperparameter
params:
  LEARNING_RATE: 0.0003
  PROTEIN_EMBEDDING_DIM: 1100
  LABEL_EMBEDDING_DIM: 1024
  LATENT_EMBEDDING_DIM: 1024
  OUTPUT_DIM: 1024
  OUTPUT_NUM_LAYERS: 2
  NUM_EPOCHS: 3
  GRADIENT_ACCUMULATION_STEPS: 1 # 1 is essentially no gradient accumulation
  POS_WEIGHT: 50 #671.7130737304688
  
  # Sequence and label encoders
  TRAIN_SEQUENCE_ENCODER: False
  TRAIN_LABEL_ENCODER: False
  TRAIN_PROJECTION_HEAD: True
  NORMALIZE_PROBABILITIES: False
  LABEL_ENCODER_CHECKPOINT: microsoft/biogpt

  # Batch sizes
  TRAIN_BATCH_SIZE: 256
  VALIDATION_BATCH_SIZE: 32
  TEST_BATCH_SIZE: 128

  # Sampling
  IN_BATCH_SAMPLING: False # Not implemented
  TRAIN_LABEL_SAMPLE_SIZE: 1000 # Set to null if you want to use all labels
  # TODO: This doesn't work yet because of find_optimal_threshold
  VALIDATION_LABEL_SAMPLE_SIZE: null # Set to null if you want to use all labels
  LABEL_BATCH_SIZE_LIMIT: 400

  # Subset fractions (for rapid prototyping; set to 1 for final model)
  TRAIN_SUBSET_FRACTION: 1 # Set to 1.0 if you want to use all data
  VALIDATION_SUBSET_FRACTION: 1 # Set to 1.0 if you want to use all data
  TEST_SUBSET_FRACTION: 1 # Set to 1.0 if you want to use all data

  # Constants
  SEED: 42
  NUM_LABELS: 32102
  VALIDATIONS_PER_EPOCH: 5
  NUM_WORKERS: 3
  DECISION_TH: null # Set to null if you want to use the best threshold from validation

#Constants for protein encoder model (e.g. ProteInfer). Not really params since 
# we are not going to change these.
embed_sequences_params:
  INPUT_CHANNELS: 20
  OUTPUT_CHANNELS: 1100
  KERNEL_SIZE: 9
  DILATION_BASE: 3
  NUM_RESNET_BLOCKS: 5
  BOTTLENECK_FACTOR: 0.5

# Paths to data, vocabularies, embeddings, and models
relative_paths:
  # ProteInfer data paths
  TRAIN_DATA_PATH: data/swissprot/proteinfer_splits/random/train_GO.fasta
  VAL_DATA_PATH: data/swissprot/proteinfer_splits/random/dev_GO.fasta
  TEST_DATA_PATH: data/swissprot/proteinfer_splits/random/test_GO.fasta
  FULL_DATA_PATH: data/swissprot/proteinfer_splits/random/full_GO.fasta

  # Zero shot data paths
  ZERO_SHOT_DATA_PATH: data/zero_shot/SwissProt_2023_unseen_sequences_and_labels.fasta

  # Vocabulary paths
  VOCABULARIES_DIR: data/vocabularies
  AMINO_ACID_VOCAB_PATH: data/vocabularies/amino_acid_vocab.json
  GO_LABEL_VOCAB_PATH: data/vocabularies/GO_label_vocab.json
  SEQUENCE_ID_VOCAB_PATH: data/vocabularies/sequence_id_vocab.json
  GO_ANNOTATIONS_PATH: data/annotations/go_annotations_2019_07_01.pkl

  # Embeddings paths (if using frozen pre-trained models)
  LABEL_EMBEDDING_PATH: data/embeddings/frozen_BioGPT_label_embeddings.pkl
  SEQUENCE_EMBEDDING_PATH: data/embeddings/frozen_proteinfer_sequence_embeddings.pkl
 
  # Where to save the model
  OUTPUT_MODEL_DIR: models/ProTCL

  # Where to save results
  RESULTS_DIR: results/

  PARENTHOOD_LIB_PATH: data/vocabularies/parenthood.json.gz
  PROTEINFER_WEIGHTS_PATH: 'models/proteinfer/GO_model_weights.pkl'