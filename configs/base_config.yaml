---
# Parameters for model training
#TODO: Optimizer can also be a hyperparameter
params:
  LEARNING_RATE: 0.0003
  PROTEIN_EMBEDDING_DIM: 1100
  LABEL_EMBEDDING_DIM: 1024
  LATENT_EMBEDDING_DIM: 1024
  OUTPUT_DIM: 1024
  OUTPUT_NUM_LAYERS: 2
  NUM_EPOCHS: 2
  GRADIENT_ACCUMULATION_STEPS: 1 # 1 = no gradient accumulation
  OPTIMIZATION_METRIC_NAME: map_micro #only micro metrics are supported if sampling labels in validation
  DECISION_TH_METRIC_NAME: f1_micro
  
  #Losses. Only the parameters for selected loss will be used
  LOSS_FN: FocalLoss #Currently supported: BCE, FocalLoss, BatchWeightedBCE
  FOCAL_LOSS_GAMMA: 2.0
  FOCAL_LOSS_ALPHA: 0.25
  BCE_POS_WEIGHT: 25 # 671.7130737304688


  # Sequence and label encoders
  TRAIN_SEQUENCE_ENCODER: False
  TRAIN_LABEL_ENCODER: False
  TRAIN_PROJECTION_HEAD: True
  NORMALIZE_PROBABILITIES: False
  LABEL_ENCODER_CHECKPOINT: microsoft/biogpt

  # Batch sizes
  TRAIN_BATCH_SIZE: 128
  VALIDATION_BATCH_SIZE: 128
  TEST_BATCH_SIZE: 32

  # Sampling
  TRAIN_LABEL_SAMPLE_SIZE: 2000 # Set to null if you want to use all labels
  VALIDATION_LABEL_SAMPLE_SIZE: 2000 # Set to null if you want to use all labels

  # Subset fractions (for rapid prototyping; set to 1 for final model)
  TRAIN_SUBSET_FRACTION: 0.01 # Set to 1.0 if you want to use all data
  VALIDATION_SUBSET_FRACTION: 0.1 # Set to 1.0 if you want to use all data
  TEST_SUBSET_FRACTION: 0.1 # Set to 1.0 if you want to use all data

  # Constants
  SEED: 42
  VALIDATIONS_PER_EPOCH: 3
  NUM_WORKERS: 1
  DECISION_TH: null # Set to null if you want to use the best threshold from validation
  LABEL_BATCH_SIZE_LIMIT: 128 # Maximum number of labels that can be passed to the label encoder at once (to avoid OOM errors)
  SEQUENCE_BATCH_SIZE_LIMIT: 128 # Maximum number of sequences that can be passed to the sequence encoder at once (to avoid OOM errors)

#Constants for protein encoder model (e.g. ProteInfer). Not really params since 
# we are not going to change these.
embed_sequences_params:
  INPUT_CHANNELS: 20
  OUTPUT_CHANNELS: 1100
  KERNEL_SIZE: 9
  DILATION_BASE: 3
  NUM_RESNET_BLOCKS: 5
  BOTTLENECK_FACTOR: 0.5
  PROTEINFER_NUM_LABELS: 32102

# Paths to data, vocabularies, embeddings, and models
paths:
  # Paths referenced relative to DATA_PATH (will have DATA_PATH prepended)
  data_paths: 
    # ProteInfer data paths
    TRAIN_DATA_PATH: swissprot/proteinfer_splits/random/train_GO.fasta
    VAL_DATA_PATH: swissprot/proteinfer_splits/random/dev_GO.fasta
    TEST_DATA_PATH: swissprot/proteinfer_splits/random/test_GO.fasta
    FULL_DATA_PATH: swissprot/proteinfer_splits/random/full_GO.fasta # used to generate vocabularies

    # Zero shot data paths
    ZERO_SHOT_DATA_PATH: zero_shot/SwissProt_2023_unseen_sequences_and_labels.fasta

    # Vocabulary paths
    VOCABULARIES_DIR: vocabularies/proteinfer
    GO_ANNOTATIONS_PATH: annotations/go_annotations_2019_07_01.pkl

    # Embeddings paths (if using frozen pre-trained models)
    LABEL_EMBEDDING_PATH: embeddings/proteinfer/frozen_BioGPT_label_embeddings.pkl
    SEQUENCE_EMBEDDING_PATH: embeddings/proteinfer/frozen_proteinfer_sequence_embeddings.pkl

    PARENTHOOD_LIB_PATH: vocabularies/parenthood.json.gz
    PROTEINFER_WEIGHTS_PATH: models/proteinfer/GO_model_weights.pkl
    
  # Paths referenced relative to OUTPUT_PATH (will have OUTPUT_PATH prepended)
  output_paths:
    # Where to save the model
    OUTPUT_MODEL_DIR: checkpoints/

    # Where to save results
    RESULTS_DIR: results/

    # Where to log
    LOG_DIR: logs/