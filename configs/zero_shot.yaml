---
# Parameters for model training
#TODO: Optimizer can also be a hyperparameter
params:
  LEARNING_RATE: 0.0003
  PROTEIN_EMBEDDING_DIM: 1100
  LABEL_EMBEDDING_DIM: 1024
  LATENT_EMBEDDING_DIM: 1024
  OUTPUT_DIM: 1024
  OUTPUT_NUM_LAYERS: 2
  NUM_EPOCHS: 20
  GRADIENT_ACCUMULATION_STEPS: 1 # 1 is essentially no gradient accumulation
  POS_WEIGHT: 50 #671.7130737304688
  
  # Sequence and label encoders
  TRAIN_SEQUENCE_ENCODER: False
  TRAIN_LABEL_ENCODER: False
  TRAIN_PROJECTION_HEAD: True
  NORMALIZE_PROBABILITIES: False
  LABEL_ENCODER_CHECKPOINT: microsoft/biogpt

  # Batch sizes
  TRAIN_BATCH_SIZE: 128
  VALIDATION_BATCH_SIZE: 128
  TEST_BATCH_SIZE: 32

  # Sampling
  TRAIN_LABEL_SAMPLE_SIZE: 2000 # Set to null if you want to use all labels
  VALIDATION_LABEL_SAMPLE_SIZE: 2000 # Set to null if you want to use all labels

  # Subset fractions (for rapid prototyping; set to 1 for final model)
  TRAIN_SUBSET_FRACTION: 1 # Set to 1.0 if you want to use all data
  VALIDATION_SUBSET_FRACTION: 1 # Set to 1.0 if you want to use all data
  TEST_SUBSET_FRACTION: 1 # Set to 1.0 if you want to use all data

  # Constants
  SEED: 42
  EPOCHS_PER_VALIDATION: 3
  NUM_WORKERS: 3
  DECISION_TH: null # Set to null if you want to use the best threshold from validation
  LABEL_BATCH_SIZE_LIMIT_NO_GRAD: 300 # Maximum number of labels that can be passed to the label encoder at once (to avoid OOM errors)
  SEQUENCE_BATCH_SIZE_LIMIT_NO_GRAD: 300 # Maximum number of sequences that can be passed to the sequence encoder at once (to avoid OOM errors)

#Constants for protein encoder model (e.g. ProteInfer). Not really params since 
# we are not going to change these.
embed_sequences_params:
  INPUT_CHANNELS: 20
  OUTPUT_CHANNELS: 1100
  KERNEL_SIZE: 9
  DILATION_BASE: 3
  NUM_RESNET_BLOCKS: 5
  BOTTLENECK_FACTOR: 0.5
  PROTEINFER_NUM_LABELS: 32102

# Paths to data, vocabularies, embeddings, and models
relative_paths:
  # ProteInfer data paths
  # TRAIN_DATA_PATH: data/swissprot/proteinfer_splits/random/train_GO.fasta
  # VAL_DATA_PATH: data/swissprot/proteinfer_splits/random/dev_GO.fasta
  # TEST_DATA_PATH: data/swissprot/proteinfer_splits/random/test_GO.fasta
  # FULL_DATA_PATH: data/swissprot/proteinfer_splits/random/full_GO.fasta # used to generate vocabularies

  # Zero shot data paths
  ZERO_SHOT_DATA_PATH: data/zero_shot/SwissProt_2023_unseen_sequences_and_labels.fasta

  # Vocabulary paths
  VOCABULARIES_DIR: data/vocabularies/zero_shot
  GO_ANNOTATIONS_PATH: data/annotations/go_annotations_2023_07_23.pkl

  # Embeddings paths (if using frozen pre-trained models)
  # LABEL_EMBEDDING_PATH: data/embeddings/proteinfer/frozen_BioGPT_label_embeddings.pkl
  # SEQUENCE_EMBEDDING_PATH: data/embeddings/proteinfer/frozen_proteinfer_sequence_embeddings.pkl
 
  # Where to save the model
  OUTPUT_MODEL_DIR: models/ProTCL/zero_shot

  # Where to save results
  RESULTS_DIR: results/

  PARENTHOOD_LIB_PATH: data/vocabularies/parenthood.json.gz
  PROTEINFER_WEIGHTS_PATH: 'models/proteinfer/GO_model_weights.pkl'