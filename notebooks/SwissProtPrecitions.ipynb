{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "curdir = Path(os.getcwd())\n",
    "sys.path.append(str(curdir.parent.absolute()))\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from src.utils.data import read_fasta\n",
    "from src.data.datasets import ProteinDataset\n",
    "import numpy as np\n",
    "from src.utils.data import read_pickle, save_to_pickle,read_json\n",
    "from src.utils.evaluation import metrics_per_label_df\n",
    "from torchmetrics.classification import AveragePrecision,Specificity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from src.utils.losses import FocalLoss\n",
    "from src.utils.evaluation import EvalMetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_list_to_df(fasta_list):\n",
    "    df = pd.DataFrame([(seq,id,\" \".join(labs)) for seq,id,labs in fasta_list],columns=['sequence','id','labels'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wha can change between 2019 and 2024?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_pickle('../data/annotations/go_annotations_may_2024.pkl')\n",
    "annotations_old = pd.read_pickle('../data/annotations/go_annotations_2019_07_01.pkl')\n",
    "p2024 = read_json('../data/vocabularies/parenthood_may_2024.json')\n",
    "p2019 = read_json('../data/vocabularies/parenthood_2019.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations['name'] = annotations['name'].str.lower()\n",
    "annotations['label'] = annotations['name'].str.lower()\n",
    "annotations_old['name'] = annotations_old['name'].str.lower()\n",
    "annotations_old['label'] = annotations_old['name'].str.lower()\n",
    "\n",
    "merged_on_names = annotations_old[['name','label']].reset_index().merge(annotations[['name','label']].reset_index(),how='outer',suffixes=('_old','_new'),on=['name'],indicator=True)\n",
    "merged_on_ids = annotations_old[['name','label']].reset_index().merge(annotations[['name','label']].reset_index(),how='outer',suffixes=('_old','_new'),on=['index'],indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added GO Terms:  1490\n",
      "Removed GO Terms:  1066\n",
      "Same ID, different definitions 1767\n",
      "Different IDs, same definitions 17\n"
     ]
    }
   ],
   "source": [
    "print('Added GO Terms: ',len(merged_on_ids.query('_merge==\"right_only\"')))\n",
    "print('Removed GO Terms: ',len(merged_on_ids.query('_merge==\"left_only\"')))\n",
    "temp = merged_on_ids.query('_merge==\"both\" and name_old != name_new')\n",
    "print('Same ID, different definitions',len(temp[temp['name_old'].apply(lambda x: 'obsolete' not in x)&temp['name_new'].apply(lambda x: 'obsolete' not in x)]))\n",
    "temp = merged_on_names.query('_merge==\"both\" and index_old!=index_new')\n",
    "print('Different IDs, same definitions',len(temp[temp['name'].apply(lambda x: 'obsolete' not in x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/swissprot/proteinfer_splits/random/test_GO_may_2024_pinf_labels.fasta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m test_2019 \u001b[38;5;241m=\u001b[39m fasta_list_to_df(read_fasta(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/swissprot/proteinfer_splits/random/test_GO.fasta\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      2\u001b[0m test_2024 \u001b[38;5;241m=\u001b[39m fasta_list_to_df(read_fasta(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/swissprot/proteinfer_splits/random/test_GO_may_2024.fasta\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m test_2024_pinf_labels \u001b[38;5;241m=\u001b[39m fasta_list_to_df(\u001b[43mread_fasta\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/swissprot/proteinfer_splits/random/test_GO_may_2024_pinf_labels.fasta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      4\u001b[0m test_2019[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_2019[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28msorted\u001b[39m(x\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m      5\u001b[0m test_2024[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_2024[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28msorted\u001b[39m(x\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[0;32m~/ProteinFunctions/src/utils/data.py:60\u001b[0m, in \u001b[0;36mread_fasta\u001b[0;34m(data_path, sep)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mReads a FASTA file and returns a list of tuples containing sequences, ids, and labels.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m sequences_with_ids_and_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m \u001b[43mSeqIO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfasta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     61\u001b[0m     sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(record\u001b[38;5;241m.\u001b[39mseq)\n\u001b[1;32m     62\u001b[0m     components \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mdescription\u001b[38;5;241m.\u001b[39msplit(sep)\n",
      "File \u001b[0;32m~/anaconda3/envs/protein_functions_310/lib/python3.10/site-packages/Bio/SeqIO/__init__.py:613\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(handle, format, alphabet)\u001b[0m\n\u001b[1;32m    611\u001b[0m iterator_generator \u001b[38;5;241m=\u001b[39m _FormatToIterator\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iterator_generator:\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01min\u001b[39;00m AlignIO\u001b[38;5;241m.\u001b[39m_FormatToIterator:\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;66;03m# Use Bio.AlignIO to read in the alignments\u001b[39;00m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (r \u001b[38;5;28;01mfor\u001b[39;00m alignment \u001b[38;5;129;01min\u001b[39;00m AlignIO\u001b[38;5;241m.\u001b[39mparse(handle, \u001b[38;5;28mformat\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m alignment)\n",
      "File \u001b[0;32m~/anaconda3/envs/protein_functions_310/lib/python3.10/site-packages/Bio/SeqIO/FastaIO.py:190\u001b[0m, in \u001b[0;36mFastaIterator.__init__\u001b[0;34m(self, source, alphabet)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alphabet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe alphabet argument is no longer supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFasta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/protein_functions_310/lib/python3.10/site-packages/Bio/SeqIO/Interfaces.py:58\u001b[0m, in \u001b[0;36mSequenceIterator.__init__\u001b[0;34m(self, source, alphabet, mode, fmt)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe alphabet argument is no longer supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, _PathLikeTypes):\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_close_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/swissprot/proteinfer_splits/random/test_GO_may_2024_pinf_labels.fasta'"
     ]
    }
   ],
   "source": [
    "test_2019 = fasta_list_to_df(read_fasta('../data/swissprot/proteinfer_splits/random/test_GO.fasta'))\n",
    "test_2024 = fasta_list_to_df(read_fasta('../data/swissprot/proteinfer_splits/random/test_GO_may_2024.fasta'))\n",
    "test_2024_pinf_labels = fasta_list_to_df(read_fasta('../data/swissprot/proteinfer_splits/random/test_GO_may_2024_pinf_labels.fasta'))\n",
    "test_2019['labels'] = test_2019['labels'].apply(lambda x: sorted(x.strip().split(' ')))\n",
    "test_2024['labels'] = test_2024['labels'].apply(lambda x: sorted(x.strip().split(' ')))\n",
    "test_2024_pinf_labels['labels'] = test_2024_pinf_labels['labels'].apply(lambda x: sorted(x.strip().split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51751, 3), (51616, 3))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2019.shape,test_2024.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22015"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([ j for i in test_2024['labels'] for j in i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged = test_2019.merge(test_2024,how='inner',on='id',suffixes=('_old','_new'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pct_added_terms(x):\n",
    "    old = set(x['labels_old'])\n",
    "    new = set(x['labels_new'])\n",
    "    return len( new - old )*100/len(new)\n",
    "def get_pct_removed_terms(x):\n",
    "    old = set(x['labels_old'])\n",
    "    new = set(x['labels_new'])\n",
    "    return len( old - new)*100/len(old)\n",
    "\n",
    "def iou(x):\n",
    "    old = set(x['labels_old'])\n",
    "    new = set(x['labels_new'])\n",
    "    return len( old & new)*100/len( old.union(new))\n",
    "\n",
    "test_merged['pct_added_terms'] = test_merged.apply(get_pct_added_terms,axis=1)\n",
    "test_merged['pct_removed_terms'] = test_merged.apply(get_pct_removed_terms,axis=1)\n",
    "test_merged['pct_iou'] = test_merged.apply(iou,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_added_terms</th>\n",
       "      <th>pct_removed_terms</th>\n",
       "      <th>pct_iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51616.000000</td>\n",
       "      <td>51616.000000</td>\n",
       "      <td>51616.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.826461</td>\n",
       "      <td>25.775540</td>\n",
       "      <td>65.808443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.775159</td>\n",
       "      <td>16.547986</td>\n",
       "      <td>17.871252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.703704</td>\n",
       "      <td>14.583333</td>\n",
       "      <td>58.139535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.771930</td>\n",
       "      <td>23.728814</td>\n",
       "      <td>68.085106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>78.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pct_added_terms  pct_removed_terms       pct_iou\n",
       "count     51616.000000       51616.000000  51616.000000\n",
       "mean         14.826461          25.775540     65.808443\n",
       "std          16.775159          16.547986     17.871252\n",
       "min           0.000000           0.000000      0.000000\n",
       "25%           3.703704          14.583333     58.139535\n",
       "50%           8.771930          23.728814     68.085106\n",
       "75%          20.000000          33.333333     78.571429\n",
       "max         100.000000         100.000000    100.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_merged[['pct_added_terms','pct_removed_terms','pct_iou']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_test = read_fasta('../data/zero_shot/SwissProt_2023_unseen_sequences_and_labels.fasta')\n",
    "full_go = read_fasta('../data/swissprot/proteinfer_splits/random/full_GO.fasta')\n",
    "\n",
    "unseen_terms = set([j for i in unseen_test for j in i[-1]])\n",
    "unseen_seqs = set([i[0] for i in unseen_test])\n",
    "unseen_seq_ids = set([i[1] for i in unseen_test])\n",
    "\n",
    "full_go_terms = set([j for i in full_go for j in i[-1]])\n",
    "new =  set(annotations.index) - set(annotations_old.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New annotations from new terms: 228\n",
      "New annotations: 1260\n",
      "New predicted labels all swissprot 544\n"
     ]
    }
   ],
   "source": [
    "print('New annotations from new terms:', len(unseen_terms))\n",
    "print('New annotations:', len(new))\n",
    "print('New predicted labels all swissprot',len(set(labels.columns)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sp = read_fasta('../data/swissprot/swissprot_2023.fasta')\n",
    "id2seq = {id:seq for seq,id,_ in all_sp}\n",
    "\n",
    "for df in [labels,logits]:\n",
    "    df['sequence'] = list(df.index.map(id2seq))\n",
    "\n",
    "    #Identify sequences based on proteinfer's split\n",
    "    seq2split = {\n",
    "    **{seq:'train' for seq,_,_ in read_fasta('../data/swissprot/proteinfer_splits/random/train_GO.fasta')},\n",
    "    **{seq:'val' for seq,_,_ in read_fasta('../data/swissprot/proteinfer_splits/random/dev_GO.fasta')},\n",
    "    **{seq:'test' for seq,_,_ in read_fasta('../data/swissprot/proteinfer_splits/random/test_GO.fasta')}\n",
    "    }\n",
    "\n",
    "    df['split'] = df['sequence'].map(seq2split).fillna('new')\n",
    "\n",
    "    df.set_index(['sequence','split'],append=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some proteins in proteinfer dataset that don't appear in all swissprot data. Less than 0.3% of proteinfer sequences. It's just proteins that have \"INLL\" appended at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "del_seqs = set([i[0] for i in full_go]) - set(id2seq.values())\n",
    "full_go_seq2ids = defaultdict(list)\n",
    "for seq,id,_ in full_go:\n",
    "    full_go_seq2ids[seq].append(id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2965899806164097"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(del_seqs)*100/len(full_go)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Q9GLP6'],\n",
       " ['Q11098'],\n",
       " ['P17019'],\n",
       " ['Q90632'],\n",
       " ['Q96SE0'],\n",
       " ['Q5H9K5'],\n",
       " ['P63034'],\n",
       " ['Q96ME1'],\n",
       " ['A8WRP9'],\n",
       " ['Q09M05']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[full_go_seq2ids[i] for i in del_seqs][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unseen_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_sp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m unseen_test_df \u001b[38;5;241m=\u001b[39m fasta_list_to_df(unseen_test)\n\u001b[0;32m----> 2\u001b[0m all_sp_df \u001b[38;5;241m=\u001b[39m fasta_list_to_df(\u001b[43mall_sp\u001b[49m)\n\u001b[1;32m      4\u001b[0m all_sp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m all_sp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28msorted\u001b[39m(x\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGO:0003674\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m      5\u001b[0m unseen_test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m unseen_test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28msorted\u001b[39m(x\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_sp' is not defined"
     ]
    }
   ],
   "source": [
    "unseen_test_df = fasta_list_to_df(unseen_test)\n",
    "all_sp_df = fasta_list_to_df(all_sp)\n",
    "\n",
    "all_sp_df['labels'] = all_sp_df['labels'].apply(lambda x: sorted(x.replace('GO:0003674','').replace('  ',' ').strip().split(' ')))\n",
    "unseen_test_df['labels'] = unseen_test_df['labels'].apply(lambda x: sorted(x.strip().split(' ')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0117) tensor(0.0619)\n",
      "{'f1_macro': tensor(0.0393), 'f1_micro': tensor(0.0251), 'precision_macro': tensor(0.0341), 'recall_macro': tensor(0.0925)}\n",
      "{'f1_macro': tensor(0.0020), 'f1_micro': tensor(0.0022), 'precision_macro': tensor(0.7317), 'recall_macro': tensor(0.0011)}\n"
     ]
    }
   ],
   "source": [
    "from torcheval.metrics import MultilabelAUPRC, BinaryAUPRC\n",
    "eval_metrics = EvalMetrics(device='cpu')\n",
    "\n",
    "\n",
    "for split in [\n",
    "              #'val',\n",
    "              'test',\n",
    "              #'new'\n",
    "              ]:\n",
    "    \n",
    "    label_mask = labels.query('split == @split').sum(axis=0)>=0\n",
    "    label_mask = list(label_mask[label_mask].index)\n",
    "\n",
    "    sequence_mask = labels.query('split == @split').sum(axis=1)>=0\n",
    "    sequence_mask = list(sequence_mask[sequence_mask].index)\n",
    "\n",
    "\n",
    "    mAP_micro = BinaryAUPRC(device='cpu')\n",
    "    mAP_macro = MultilabelAUPRC(device='cpu',\n",
    "                                num_labels=len(label_mask))\n",
    "    metrics=eval_metrics.get_metric_collection_with_regex(pattern=\"(f1_m.*)|(precision_macro)|(recall_macro)\",\n",
    "                                                                    threshold=0.3,\n",
    "                                                            num_labels=len(label_mask)\n",
    "                                                            )\n",
    "    \n",
    "    probabilities = torch.sigmoid(torch.tensor(logits.query('split == @split').loc[sequence_mask][label_mask].values))\n",
    "    y = torch.tensor(labels.query('split == @split').loc[sequence_mask][label_mask].values)\n",
    "\n",
    "\n",
    "    print(mAP_micro.update(probabilities.flatten(), y.flatten()).compute(),mAP_macro.update(probabilities, y).compute())\n",
    "    print(metrics(probabilities, y))\n",
    "    metrics.reset()\n",
    "    print(metrics(probabilities, 1-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_df = pd.DataFrame(probabilities,\n",
    "                                columns = logits.query('split == @split').loc[sequence_mask][label_mask].columns,\n",
    "                                index = logits.query('split == @split').loc[sequence_mask][label_mask].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=(probabilities_df>0.9)&(labels.query('split == @split').loc[sequence_mask][label_mask]==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0352)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(y[probabilities>0.99].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  225,   840,  1002,  2066,  2071,  4416,  5082,  5286,  5286,  9112,\n",
       "          9113,  9653,  9653,  9783,  9784,  9785,  9953,  9958,  9962, 10231,\n",
       "         10247, 11231, 11474, 11476, 11477, 11481, 11487, 11489, 11493, 11499,\n",
       "         11503, 11504, 11505, 11508, 11510, 12198, 12826, 13434, 13564, 13583,\n",
       "         16123, 16123, 16900, 16942, 16942, 16945, 16945, 16946, 16946, 17633,\n",
       "         17922, 18176, 18940, 18941, 19515, 19516, 20691, 21503, 21650, 23392,\n",
       "         23396, 23396, 24572, 24573, 24574, 24575, 25507, 25507, 25881, 25886,\n",
       "         25887, 26006, 26006, 26007, 26008, 26009, 26010, 26010, 26011, 26012,\n",
       "         26013, 26014, 26015, 26016, 26017, 26018, 26019, 26020, 26748, 27477,\n",
       "         27480, 27482, 27491, 27505, 27544, 27545, 28216, 28216, 28230, 28390,\n",
       "         28392, 28394, 28395, 28396, 28794, 28795, 29020, 29097, 29456, 29457,\n",
       "         29458, 29459, 29467, 29468, 29469, 29470, 29471, 29472, 29473, 29474,\n",
       "         29475, 29478, 29480, 29492, 29493, 29494, 29494, 29495, 29500, 30759,\n",
       "         32925, 33371, 33375, 33375, 33376, 33376, 33377, 33377, 33378, 33378,\n",
       "         33379, 33379, 33380, 33380, 33381, 33388, 33389, 33390, 33391, 33392,\n",
       "         33393, 33400, 33403, 33404, 33405, 33406, 33408, 33409, 33410, 33412,\n",
       "         33420, 33423, 33425, 33426, 33427, 33429, 33435, 33436, 33442, 33443,\n",
       "         36646, 36738, 36742, 37045, 37057, 37106, 37122, 37130, 37158, 37160,\n",
       "         37162, 37164, 37165, 37166, 37168, 37169, 37171, 37173, 37174, 37175,\n",
       "         37179, 37180, 37181, 37182, 37183, 37185, 37186, 37189, 37190, 37193,\n",
       "         37194, 37195, 37198, 37199, 37200, 37201, 37202, 37203, 37204, 37205,\n",
       "         37206, 37207, 37208, 37209, 37220, 37234, 37244, 37246, 37249, 37255,\n",
       "         37468, 37468, 37858, 37858, 37859, 37860, 37861, 37862, 37863, 37864,\n",
       "         37865, 37866, 37893, 40169, 40187, 40496, 40506, 41620, 41620, 41738,\n",
       "         41822, 41860, 41861, 42340, 42819, 43231, 43359, 43417, 43418, 43419,\n",
       "         43420, 43421, 43540, 43541, 43542, 43543, 43544, 43608, 43609, 43620,\n",
       "         43626, 43637, 43640, 43645, 43683, 43730, 43961, 43962, 43963, 43964,\n",
       "         43965, 43966, 44101, 44230, 44673, 44674, 44675, 44676, 44677, 44678,\n",
       "         44681, 46825, 47352, 47523, 48015, 48016, 48027, 48035, 48040, 48043,\n",
       "         48045, 48063, 48278, 48278, 48283, 48283, 48284, 48286, 48291, 48291,\n",
       "         48292, 48293, 48293, 48294, 48294, 48295, 48295, 48296, 48296, 48297,\n",
       "         48297, 48298, 48298, 48299, 48299, 48300, 48300, 48301, 48301, 48302,\n",
       "         48302, 48303, 48303, 48304, 48309, 48309, 48637, 48638, 48639, 48692,\n",
       "         48739, 48740, 48892, 48893, 48894, 48895, 48896, 48916, 48917, 50332,\n",
       "         50333, 50345, 50346, 50348, 50350, 50363, 50376, 50378, 50533, 50534,\n",
       "         50601, 50602, 50698, 50983, 51445, 51457, 51462, 51464]),\n",
       " tensor([439, 439, 439, 358, 358, 452, 440, 208, 632, 452, 452, 306, 307, 413,\n",
       "         413, 413, 196, 196, 196, 558, 662, 358, 413, 413, 413, 413, 413, 413,\n",
       "         413, 413, 413, 413, 413, 413, 413, 413,  45, 358, 413, 413, 311, 312,\n",
       "         632,  93, 116,  93, 116,  93, 116, 558, 238,  45, 168, 168,  45,  45,\n",
       "         452,  93, 439, 293, 293, 358, 662, 632, 632, 632, 383, 439, 358, 358,\n",
       "         358, 289, 558, 558, 558, 558, 289, 558, 558, 558, 558, 558, 558, 558,\n",
       "         558, 558, 558, 558, 452, 196, 196, 196, 196, 196, 632, 632, 383, 439,\n",
       "         208, 297, 297, 297, 297, 297, 558, 558, 632, 452, 558, 558, 558, 558,\n",
       "         558, 558, 558, 558, 558, 558, 558, 558, 558, 558, 558, 413, 413, 289,\n",
       "         413, 413, 413, 439, 358, 452, 356, 452, 356, 452, 356, 452, 356, 452,\n",
       "         356, 452, 356, 452, 452, 452, 452, 452, 452, 452, 452, 452, 452, 452,\n",
       "         452, 452, 452, 452, 452, 452, 452, 452, 452, 452, 452, 452, 452, 452,\n",
       "         452, 452, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413,\n",
       "         413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413,\n",
       "         413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413,\n",
       "         413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 383, 439, 293, 413,\n",
       "         413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 358,\n",
       "         632, 558, 615, 439, 439, 632, 457, 413, 413, 413, 413, 413, 413, 413,\n",
       "         413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 196, 196,\n",
       "         413, 413, 413, 413, 413, 413, 413, 208, 358, 558, 558, 558, 558, 558,\n",
       "         358, 662, 632, 196, 413, 413, 413, 413, 413, 413, 413, 413, 293, 358,\n",
       "         293, 358, 358, 358, 289, 558, 558, 289, 558, 289, 558, 289, 558, 289,\n",
       "         558, 289, 558, 289, 558, 289, 558, 289, 558, 289, 558, 289, 558, 289,\n",
       "         558, 558,  45, 662, 558, 558, 558, 558, 632, 632, 413, 413, 413, 413,\n",
       "         413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413, 413,\n",
       "         413, 413, 413, 413,  45, 297, 297, 297]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where((probabilities>0.99)&(y==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19598])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[probabilities>0.].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1804)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37728590"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "51683*730"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.7815197970557606e-05"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1804/37728590"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005194469234074213"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "19598/37728590"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn,fp,fn,tp = confusion_matrix(y.flatten().numpy(),(probabilities.flatten().numpy()>.3)*1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37685570, 41216, 1257, 547)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn,fp,fn,tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics import MultilabelAUPRC, BinaryAUPRC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37726428, 358, 1800, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn,fp,fn,tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0477) tensor(0.1429)\n",
      "{'f1_macro': tensor(0.0938), 'f1_micro': tensor(0.0763), 'precision_macro': tensor(0.0823), 'recall_macro': tensor(0.2208)}\n",
      "{'f1_macro': tensor(0.0023), 'f1_micro': tensor(0.0024), 'precision_macro': tensor(0.6941), 'recall_macro': tensor(0.0012)}\n"
     ]
    }
   ],
   "source": [
    "eval_metrics = EvalMetrics(device='cpu')\n",
    "\n",
    "\n",
    "for split in [\n",
    "              #'val',\n",
    "              'test',\n",
    "              #'new'\n",
    "              ]:\n",
    "    \n",
    "    label_mask = labels.query('split == @split').sum(axis=0)>0\n",
    "    label_mask = list(label_mask[label_mask].index)\n",
    "\n",
    "    sequence_mask = labels.query('split == @split').sum(axis=1)>=0\n",
    "    sequence_mask = list(sequence_mask[sequence_mask].index)\n",
    "\n",
    "\n",
    "    mAP_micro = BinaryAUPRC(device='cpu')\n",
    "    mAP_macro = MultilabelAUPRC(device='cpu',\n",
    "                                num_labels=len(label_mask))\n",
    "    metrics=eval_metrics.get_metric_collection_with_regex(pattern=\"(f1_m.*)|(precision_macro)|(recall_macro)\",\n",
    "                                                                    threshold=0.3,\n",
    "                                                            num_labels=len(label_mask)\n",
    "                                                            )\n",
    "    \n",
    "    probabilities = torch.sigmoid(torch.tensor(logits.query('split == @split').loc[sequence_mask][label_mask].values))\n",
    "    y = torch.tensor(labels.query('split == @split').loc[sequence_mask][label_mask].values)\n",
    "\n",
    "\n",
    "    print(mAP_micro.update(probabilities.flatten(), y.flatten()).compute(),mAP_macro.update(probabilities, y).compute())\n",
    "    print(metrics(probabilities, y))\n",
    "    metrics.reset()\n",
    "    print(metrics(probabilities, 1-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlabels\u001b[49m\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit == @split\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mloc[sequence_mask][label_mask]\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "labels.query('split == @split').loc[sequence_mask][label_mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new_labels = []\n",
    "test_new_labels_ = []\n",
    "for i in all_sp:\n",
    "    if i[0] in seq2split:\n",
    "        if seq2split[i[0]]=='test':\n",
    "            record = SeqRecord(Seq(i[0]),id=i[1],description=\" \".join(i[2]))\n",
    "            test_new_labels.append(record)\n",
    "            test_new_labels_.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51687"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = set([i[0] for i in test_new_labels_])\n",
    "labs=labels.query('sequence in @seqs')\n",
    "lags=logits.query('sequence in @seqs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0478) tensor(0.1399)\n"
     ]
    }
   ],
   "source": [
    "logs = pd.read_parquet(\"../outputs/results/test_1_logits_zero_shot_pinf_test.parquet\").drop('GO:0003674',axis=1)\n",
    "labs = pd.read_parquet(\"../outputs/results/test_1_labels_zero_shot_pinf_test.parquet\").drop('GO:0003674',axis=1)\n",
    "mAP_micro = BinaryAUPRC(device='cpu')\n",
    "mAP_macro = MultilabelAUPRC(device='cpu',\n",
    "                            num_labels=labs.shape[-1])\n",
    "\n",
    "probabilities = torch.sigmoid(torch.tensor(logs.values))\n",
    "y = torch.tensor(labs.values)\n",
    "\n",
    "print(mAP_micro.update(probabilities.flatten(), y.flatten()).compute(),mAP_macro.update(probabilities, y).compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_mask = labels.query('split == @split').sum(axis=0)>0\n",
    "label_mask = list(label_mask[label_mask].index)\n",
    "\n",
    "sequence_mask = labels.query('split == @split').sum(axis=1)>0\n",
    "sequence_mask = list(sequence_mask[sequence_mask].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0212) tensor(0.0431)\n"
     ]
    }
   ],
   "source": [
    "split = 'new'\n",
    "label_mask = labels.query('split == @split').sum(axis=0)>0\n",
    "label_mask = list(label_mask.index) #list(unseen_terms&set(labels.query('split == @split').columns)) \n",
    "\n",
    "mAP_micro = BinaryAUPRC(device='cpu')\n",
    "mAP_macro = MultilabelAUPRC(device='cpu',\n",
    "                            num_labels=len(label_mask))\n",
    "\n",
    "probabilities = torch.sigmoid(torch.tensor(logits.query('split == @split')[label_mask].values))\n",
    "y = torch.tensor(labels.query('split == @split')[label_mask].values)\n",
    "\n",
    "\n",
    "print(mAP_micro.update(probabilities.flatten(), y.flatten()).compute(),mAP_macro.update(probabilities, y).compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "987"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels.query('split == @split')[label_mask].sum(axis=1)>0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "logits_unseen = pd.read_parquet(\"../outputs/results/unseen_zero_shot_logits.parquet\")\n",
    "labels_unseen = pd.read_parquet(\"../outputs/results/unseen_zero_shot_labels.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([815, 227])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_590820/2934256670.py:8: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  probabilities = torch.sigmoid(torch.tensor(logits.loc[mask,cols].values))\n",
      "/tmp/ipykernel_590820/2934256670.py:9: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  y = torch.tensor(labels.loc[mask,cols].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(69730) tensor(202205.6875)\n",
      "tensor(0.0948) tensor(0.1447)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mask = set(labels.index.get_level_values(0))#&set(labels_unseen.index)\n",
    "cols = set(labels.columns) #set(labels_unseen.columns)\n",
    "\n",
    "mAP_micro = BinaryAUPRC(device='cpu')\n",
    "mAP_macro = MultilabelAUPRC(device='cpu',\n",
    "                            num_labels=len(cols))\n",
    "\n",
    "probabilities = torch.sigmoid(torch.tensor(logits.loc[mask,cols].values))\n",
    "y = torch.tensor(labels.loc[mask,cols].values)\n",
    "print(y.sum(),probabilities.sum())\n",
    "print(mAP_micro.update(probabilities.flatten(), y.flatten()).compute(),mAP_macro.update(probabilities, y).compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GO:0120257        0\n",
       "GO:0120258        0\n",
       "GO:0140928        1\n",
       "GO:0140796        1\n",
       "GO:0140795        1\n",
       "              ...  \n",
       "GO:0140678     1404\n",
       "GO:0140535     1693\n",
       "GO:0140657     2466\n",
       "GO:0140640     5604\n",
       "GO:0110165    47658\n",
       "Length: 544, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.sum(axis=0).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn,fp,fn,tp = confusion_matrix(y.flatten().numpy(),(probabilities.flatten().numpy()>.3)*1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11604433, 13629, 51221, 1468)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn,fp,fn,tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged\n",
    "\n",
    "\n",
    "\n",
    "mask = set(labels.index.get_level_values(0))#&set(labels_unseen.index)\n",
    "cols = set(labels.columns) #set(labels_unseen.columns)\n",
    "\n",
    "mAP_micro = BinaryAUPRC(device='cpu')\n",
    "mAP_macro = MultilabelAUPRC(device='cpu',\n",
    "                            num_labels=len(cols))\n",
    "\n",
    "probabilities = torch.sigmoid(torch.tensor(logits.loc[mask,cols].values))\n",
    "y = torch.tensor(labels.loc[mask,cols].values)\n",
    "print(y.sum(),probabilities.sum())\n",
    "print(mAP_micro.update(probabilities.flatten(), y.flatten()).compute(),mAP_macro.update(probabilities, y).compute())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein_functions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
