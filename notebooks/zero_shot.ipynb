{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import wget\n",
    "\n",
    "curdir = Path(os.getcwd())\n",
    "sys.path.append(str(curdir.parent.absolute()))\n",
    "\n",
    "from src.utils.data import read_fasta\n",
    "\n",
    "link = 'https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.dat.gz'\n",
    "filename = 'uniprot_sprot.dat.gz'\n",
    "unzipped_filename = 'uniprot_sprot.dat'\n",
    "\n",
    "# Download the file from the web\n",
    "wget.download(link, filename)\n",
    "\n",
    "# Unzip the downloaded file\n",
    "with gzip.open(filename, 'rb') as f_in:\n",
    "    with open(unzipped_filename, 'wb') as f_out:\n",
    "        f_out.write(f_in.read())\n",
    "\n",
    "print(f\"File {filename} has been downloaded and unzipped to {unzipped_filename}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SwissProt\n",
    "\n",
    "# Extract data from SwissProt records\n",
    "data = []\n",
    "# See https://biopython.org/docs/1.75/api/Bio.SwissProt.html and https://web.expasy.org/docs/userman.html\n",
    "with open('/home/ncorley/protein/ProteinFunctions/data/swissprot/uniprot_sprot.dat', 'r') as f:\n",
    "    records = SwissProt.parse(f)\n",
    "    for record in records:\n",
    "        # Extract sequence ID\n",
    "        seq_id = record.accessions[0]\n",
    "        \n",
    "        # Extract sequence\n",
    "        sequence = record.sequence\n",
    "\n",
    "        # Extract GO ids\n",
    "        go_ids = [ref[1] for ref in record.cross_references if ref[0] == \"GO\" and len(ref) > 0]\n",
    "        \n",
    "        # Extract free-text description\n",
    "        description = record.description\n",
    "\n",
    "        # Extract organism and organism classification\n",
    "        organism = record.organism\n",
    "        organism_classification = record.organism_classification\n",
    "\n",
    "        # Extract organelle\n",
    "        organelle = record.organelle\n",
    "        \n",
    "        # Extract CC line as a dictionary\n",
    "        cc = {}\n",
    "        for comment in record.comments:\n",
    "            key, value = comment.split(\": \", 1)\n",
    "            cc[key] = value\n",
    "        \n",
    "        data.append([seq_id, sequence, go_ids, description, organism, organism_classification, organelle, cc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q6GZX4', 'MAFSAEDVLKEYDRRRRMEALLLSLYYPNDRKLLDYKEWSPPRVQVECPKAPVEWNNPPSEKGLIVGHFSGIKYKGEKAQASEVDVNKMCCWVSKFKDAMRRYQGIQTCKIPGKVLSDLDAKIKAYNLTVEGVEGFVRYSRVTKQHVAAFLKELRHSKQYENVNLIHYILTDKRVDIQHLEKDLVKDFKALVESAHRMRQGHMINVKYILYQLLKKHGHGPDGPDILTVKTGSKGVLYDDSFRKIYTDLGWKFTPL', ['GO:0046782'], 'RecName: Full=Putative transcription factor 001R;', 'Frog virus 3 (isolate Goorha) (FV-3).', ['Viruses', 'Varidnaviria', 'Bamfordvirae', 'Nucleocytoviricota', 'Megaviricetes', 'Pimascovirales', 'Iridoviridae', 'Alphairidovirinae', 'Ranavirus'], '', {'FUNCTION': 'Transcription activation. {ECO:0000305}.'}]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(data[0])\n",
    "print(len(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into a pandas DataFrame\n",
    "df_2023 = pd.DataFrame(data, columns=[\"seq_id\", \"sequence\", \"go_ids\", \"description\", \"organism\", \"organism_classification\", \"organelle\", \"cc\"])\n",
    "\n",
    "# Create a new column with the subcellular location\n",
    "df_2023['subcellular_location'] = df_2023.cc.apply(lambda x: x['SUBCELLULAR LOCATION'] if 'SUBCELLULAR LOCATION' in x else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sequence embeddings from /home/ncorley/protein/ProteinFunctions/data/embeddings/frozen_proteinfer_sequence_embeddings.pkl\n",
    "import pickle\n",
    "\n",
    "# Load the sequence embeddings from the file\n",
    "with open('/home/ncorley/protein/ProteinFunctions/data/embeddings/frozen_proteinfer_sequence_embeddings.pkl', 'rb') as f:\n",
    "    sequence_embeddings = pickle.load(f)\n",
    "\n",
    "# Make a set of the sequence strings\n",
    "sequence_strings_2019 = set(sequence_embeddings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Q6GZX4\n",
      "1    Q6GZX3\n",
      "2    Q197F8\n",
      "3    Q197F7\n",
      "4    Q6GZX2\n",
      "Name: seq_id, dtype: object\n",
      "['Q5RDG8', 'Q027V0', 'B2UBB1', 'F4I893', 'Q6BJH5']\n",
      "Number of sequences in df_2023 but not in ProteInfer dataset: 47493\n",
      "Number of sequences in df_2023: 569793\n",
      "Number of sequences in ProteInfer dataset: 522607\n"
     ]
    }
   ],
   "source": [
    "# Find sequence ids  that are in df but not in sequence_strings\n",
    "df_2023['in_ProteInfer_dataset'] = df_2023.seq_id.apply(lambda x: x in sequence_strings_2019)\n",
    "\n",
    "# Print 5 example sequences from df.sequence\n",
    "print(df_2023.seq_id.head())\n",
    "\n",
    "# Print 5 example sequences from sequence_strings\n",
    "print(list(sequence_strings_2019)[:5])\n",
    "\n",
    "# Count the number of sequences that are in df but not in sequence_strings\n",
    "print(f\"Number of sequences in df_2023 but not in ProteInfer dataset: {df_2023.in_ProteInfer_dataset.value_counts()[False]}\")\n",
    "print(f\"Number of sequences in df_2023: {len(df_2023)}\")\n",
    "print(f\"Number of sequences in ProteInfer dataset: {len(sequence_strings_2019)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import label embeddings from /home/ncorley/protein/ProteinFunctions/data/embeddings/frozen_proteinfer_label_embeddings.pkl\n",
    "import pickle\n",
    "\n",
    "# Load the label embeddings from the file\n",
    "with open('/home/ncorley/protein/ProteinFunctions/data/embeddings/frozen_PubMedBERT_label_embeddings.pkl', 'rb') as f:\n",
    "    label_embeddings_2019 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47401\n",
      "29283\n"
     ]
    }
   ],
   "source": [
    "# Make a set of the GO labels from the label embeddings\n",
    "label_ids_2019 = set(label_embeddings_2019.keys())\n",
    "print(len(label_ids_2019))\n",
    "\n",
    "# Make a set from all the GO labels that occur in the data\n",
    "label_ids_2023 = set([item for sublist in df_2023.go_ids for item in sublist])\n",
    "print(len(label_ids_2023))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GO labels in go_label_strings but not in label_strings: 666\n",
      "['GO:0140915', 'GO:0140823', 'GO:0160074', 'GO:0110162', 'GO:0106292', 'GO:0140926', 'GO:0062158', 'GO:0140900', 'GO:0120317', 'GO:0106283']\n"
     ]
    }
   ],
   "source": [
    "# Find GO labels that are in go_label_strings but not in label_strings\n",
    "print(f\"Number of GO labels in go_label_strings but not in label_strings: {len(label_ids_2023 - label_ids_2019)}\")\n",
    "\n",
    "# Print out 10 examples of GO labels that are in go_label_strings but not in label_strings\n",
    "print(list(label_ids_2023 - label_ids_2019)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find added labels\n",
    "new_go_labels = label_ids_2023 - label_ids_2019\n",
    "\n",
    "# Find protein sequences with added labels\n",
    "df_2023['new_labels'] = df_2023.go_ids.apply(lambda x: set(x) & new_go_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with 'in_ProteInfer_dataset' == False: 47493\n",
      "Number of rows with 'in_ProteInfer_dataset' == False and 'new_labels' != set(): 917\n"
     ]
    }
   ],
   "source": [
    "# Count how many rows have 'in_Proteinfer_dataset' == False\n",
    "print(f\"Number of rows with 'in_ProteInfer_dataset' == False: {len(df_2023[df_2023.in_ProteInfer_dataset == False])}\")\n",
    "\n",
    "# Count how many rows have 'in_Proteinfer_dataset' == False and 'new_labels' != set()\n",
    "print(f\"Number of rows with 'in_ProteInfer_dataset' == False and 'new_labels' != set(): {len(df_2023[(df_2023.in_ProteInfer_dataset == False) & (df_2023.new_labels != set())])}\")\n",
    "\n",
    "# Create a new dataframe out of those that meet that criteria\n",
    "df_2023_new_sequences_and_labels = df_2023[(df_2023.in_ProteInfer_dataset == False) & (df_2023.new_labels != set())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df_2023_new_sequences_and_labels as a pickle file\n",
    "# Save to here: /home/ncorley/protein/ProteinFunctions/data/zero_shot, with the name \"SwissProt_2023_unseen_sequences_and_labels.pkl\"\n",
    "df_2023_new_sequences_and_labels.to_pickle('/home/ncorley/protein/ProteinFunctions/data/zero_shot/SwissProt_2023_unseen_sequences_and_labels.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein_functions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
