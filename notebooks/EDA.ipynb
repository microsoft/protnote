{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "curdir = Path(os.getcwd())\n",
    "sys.path.append(str(curdir.parent.absolute()))\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils.data import read_fasta\n",
    "from src.data.datasets import ProteinDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_fasta('../data/swissprot/proteinfer_splits/random/train_GO.fasta')\n",
    "val = read_fasta('../data/swissprot/proteinfer_splits/random/dev_GO.fasta')\n",
    "test = read_fasta('../data/swissprot/proteinfer_splits/random/test_GO.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [(k[0],j,\" \".join(k[1:])) for j,k in train]\n",
    "test = [(k[0],j,\" \".join(k[1:])) for j,k in test]\n",
    "val = [(k[0],j,\" \".join(k[1:])) for j,k in val]\n",
    "\n",
    "df = train + val + test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df,columns=['id','sequence','labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sequences: 522607\n"
     ]
    }
   ],
   "source": [
    "num_sequences = len(df)\n",
    "print('number of sequences:',num_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Counter()\n",
    "\n",
    "vocab = set()\n",
    "amino_freq = Counter()\n",
    "for idx,row in df.iterrows():\n",
    "    sequence = row['sequence']\n",
    "    row_labels = row['labels']\n",
    "    aa_list = list(sequence)\n",
    "    if row_labels =='':\n",
    "        print(row['id'],row['labels'])\n",
    "    vocab.update(aa_list)\n",
    "    amino_freq.update(aa_list)\n",
    "    labels.update(row_labels.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# GO Terms: 32102\n"
     ]
    }
   ],
   "source": [
    "print('# GO Terms:',len(labels.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO Terms distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     32102.000000\n",
       "mean        777.250545\n",
       "std        9114.786603\n",
       "min           1.000000\n",
       "25%           4.000000\n",
       "50%          17.000000\n",
       "75%          84.000000\n",
       "max      462356.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('GO Terms distribution')\n",
    "pd.Series(labels.values()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    522607.000000\n",
       "mean        368.042215\n",
       "std         334.721845\n",
       "min           2.000000\n",
       "25%         179.000000\n",
       "50%         303.000000\n",
       "75%         456.000000\n",
       "max       35213.000000\n",
       "Name: sequence, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Sequence length distribution')\n",
    "\n",
    "df['sequence'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PD = ProteinDataset(data_path='../data/swissprot/proteinfer_splits/random/train_GO.fasta',\n",
    "                    sequence_vocabulary_path='../data/vocabularies/amino_acid_vocab.json',\n",
    "                    label_vocabulary_path='../data/vocabularies/GO_label_vocab.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418015, 35213)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PD),PD.get_max_seq_len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32102])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from src.models.protein_encoders import Residual,ProteInfer\n",
    "i=torch.ones((8,20,100))\n",
    "#r=Residual(input_channels=20,kernel_size=9,dilation=9,bottleneck_factor=0.5,activation = torch.nn.ReLU)\n",
    "r = ProteInfer(num_labels=32102,input_channels=20,output_channels=1100,kernel_size=9,activation=torch.nn.ReLU,dilation_base=3,num_resnet_blocks=5,bottleneck_factor=0.5)\n",
    "seqs_lengths = torch.tensor([80,20,5,100,95,80,20,5])\n",
    "o=r(i,seqs_lengths)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight:torch.Size([1100, 20, 9]) <--> inferrer/conv1d/kernel:0:(1100, 20, 9)\n",
      "conv1.bias:torch.Size([1100]) <--> inferrer/conv1d/bias:0:(1100,)\n",
      "resnet_blocks.0.bn_activation_1.0.weight:torch.Size([1100]) <--> inferrer/residual_block_0/batch_normalization/gamma:0:(1100,)\n",
      "resnet_blocks.0.bn_activation_1.0.bias:torch.Size([1100]) <--> inferrer/residual_block_0/batch_normalization/beta:0:(1100,)\n",
      "resnet_blocks.0.masked_conv1.weight:torch.Size([550, 1100, 9]) <--> inferrer/residual_block_0/conv1d/kernel:0:(550, 1100, 9)\n",
      "resnet_blocks.0.masked_conv1.bias:torch.Size([550]) <--> inferrer/residual_block_0/conv1d/bias:0:(550,)\n",
      "resnet_blocks.0.bn_activation_2.0.weight:torch.Size([550]) <--> inferrer/residual_block_0/batch_normalization_1/gamma:0:(550,)\n",
      "resnet_blocks.0.bn_activation_2.0.bias:torch.Size([550]) <--> inferrer/residual_block_0/batch_normalization_1/beta:0:(550,)\n",
      "resnet_blocks.0.masked_conv2.weight:torch.Size([1100, 550, 1]) <--> inferrer/residual_block_0/conv1d_1/kernel:0:(1100, 550, 1)\n",
      "resnet_blocks.0.masked_conv2.bias:torch.Size([1100]) <--> inferrer/residual_block_0/conv1d_1/bias:0:(1100,)\n",
      "resnet_blocks.1.bn_activation_1.0.weight:torch.Size([1100]) <--> inferrer/residual_block_1/batch_normalization/gamma:0:(1100,)\n",
      "resnet_blocks.1.bn_activation_1.0.bias:torch.Size([1100]) <--> inferrer/residual_block_1/batch_normalization/beta:0:(1100,)\n",
      "resnet_blocks.1.masked_conv1.weight:torch.Size([550, 1100, 9]) <--> inferrer/residual_block_1/conv1d/kernel:0:(550, 1100, 9)\n",
      "resnet_blocks.1.masked_conv1.bias:torch.Size([550]) <--> inferrer/residual_block_1/conv1d/bias:0:(550,)\n",
      "resnet_blocks.1.bn_activation_2.0.weight:torch.Size([550]) <--> inferrer/residual_block_1/batch_normalization_1/gamma:0:(550,)\n",
      "resnet_blocks.1.bn_activation_2.0.bias:torch.Size([550]) <--> inferrer/residual_block_1/batch_normalization_1/beta:0:(550,)\n",
      "resnet_blocks.1.masked_conv2.weight:torch.Size([1100, 550, 1]) <--> inferrer/residual_block_1/conv1d_1/kernel:0:(1100, 550, 1)\n",
      "resnet_blocks.1.masked_conv2.bias:torch.Size([1100]) <--> inferrer/residual_block_1/conv1d_1/bias:0:(1100,)\n",
      "resnet_blocks.2.bn_activation_1.0.weight:torch.Size([1100]) <--> inferrer/residual_block_2/batch_normalization/gamma:0:(1100,)\n",
      "resnet_blocks.2.bn_activation_1.0.bias:torch.Size([1100]) <--> inferrer/residual_block_2/batch_normalization/beta:0:(1100,)\n",
      "resnet_blocks.2.masked_conv1.weight:torch.Size([550, 1100, 9]) <--> inferrer/residual_block_2/conv1d/kernel:0:(550, 1100, 9)\n",
      "resnet_blocks.2.masked_conv1.bias:torch.Size([550]) <--> inferrer/residual_block_2/conv1d/bias:0:(550,)\n",
      "resnet_blocks.2.bn_activation_2.0.weight:torch.Size([550]) <--> inferrer/residual_block_2/batch_normalization_1/gamma:0:(550,)\n",
      "resnet_blocks.2.bn_activation_2.0.bias:torch.Size([550]) <--> inferrer/residual_block_2/batch_normalization_1/beta:0:(550,)\n",
      "resnet_blocks.2.masked_conv2.weight:torch.Size([1100, 550, 1]) <--> inferrer/residual_block_2/conv1d_1/kernel:0:(1100, 550, 1)\n",
      "resnet_blocks.2.masked_conv2.bias:torch.Size([1100]) <--> inferrer/residual_block_2/conv1d_1/bias:0:(1100,)\n",
      "resnet_blocks.3.bn_activation_1.0.weight:torch.Size([1100]) <--> inferrer/residual_block_3/batch_normalization/gamma:0:(1100,)\n",
      "resnet_blocks.3.bn_activation_1.0.bias:torch.Size([1100]) <--> inferrer/residual_block_3/batch_normalization/beta:0:(1100,)\n",
      "resnet_blocks.3.masked_conv1.weight:torch.Size([550, 1100, 9]) <--> inferrer/residual_block_3/conv1d/kernel:0:(550, 1100, 9)\n",
      "resnet_blocks.3.masked_conv1.bias:torch.Size([550]) <--> inferrer/residual_block_3/conv1d/bias:0:(550,)\n",
      "resnet_blocks.3.bn_activation_2.0.weight:torch.Size([550]) <--> inferrer/residual_block_3/batch_normalization_1/gamma:0:(550,)\n",
      "resnet_blocks.3.bn_activation_2.0.bias:torch.Size([550]) <--> inferrer/residual_block_3/batch_normalization_1/beta:0:(550,)\n",
      "resnet_blocks.3.masked_conv2.weight:torch.Size([1100, 550, 1]) <--> inferrer/residual_block_3/conv1d_1/kernel:0:(1100, 550, 1)\n",
      "resnet_blocks.3.masked_conv2.bias:torch.Size([1100]) <--> inferrer/residual_block_3/conv1d_1/bias:0:(1100,)\n",
      "resnet_blocks.4.bn_activation_1.0.weight:torch.Size([1100]) <--> inferrer/residual_block_4/batch_normalization/gamma:0:(1100,)\n",
      "resnet_blocks.4.bn_activation_1.0.bias:torch.Size([1100]) <--> inferrer/residual_block_4/batch_normalization/beta:0:(1100,)\n",
      "resnet_blocks.4.masked_conv1.weight:torch.Size([550, 1100, 9]) <--> inferrer/residual_block_4/conv1d/kernel:0:(550, 1100, 9)\n",
      "resnet_blocks.4.masked_conv1.bias:torch.Size([550]) <--> inferrer/residual_block_4/conv1d/bias:0:(550,)\n",
      "resnet_blocks.4.bn_activation_2.0.weight:torch.Size([550]) <--> inferrer/residual_block_4/batch_normalization_1/gamma:0:(550,)\n",
      "resnet_blocks.4.bn_activation_2.0.bias:torch.Size([550]) <--> inferrer/residual_block_4/batch_normalization_1/beta:0:(550,)\n",
      "resnet_blocks.4.masked_conv2.weight:torch.Size([1100, 550, 1]) <--> inferrer/residual_block_4/conv1d_1/kernel:0:(1100, 550, 1)\n",
      "resnet_blocks.4.masked_conv2.bias:torch.Size([1100]) <--> inferrer/residual_block_4/conv1d_1/bias:0:(1100,)\n",
      "output_layer.weight:torch.Size([32102, 1100]) <--> inferrer/logits/kernel:0:(32102, 1100)\n",
      "output_layer.bias:torch.Size([32102]) <--> inferrer/logits/bias:0:(32102,)\n",
      "matched all shapes = True\n"
     ]
    }
   ],
   "source": [
    "from src.utils.data import read_pickle\n",
    "import numpy as np\n",
    "tf_weights = read_pickle('../models/proteinfer/GO_model_weights.pkl')\n",
    "\n",
    "# set new weights from loaded tf values\n",
    "matched_shapes = []\n",
    "with torch.no_grad():\n",
    "    for (name, param), (tf_name, tf_param) in zip(r.named_parameters(), tf_weights.items()):\n",
    "        \n",
    "        if (tf_param.ndim>=2):\n",
    "            tf_param =np.transpose(tf_param,\n",
    "                                   tuple(sorted(range(tf_param.ndim),reverse=True))\n",
    "                                   ) \n",
    "        \n",
    "        \n",
    "        print(f'{name}:{param.shape}','<-->',f'{tf_name}:{tf_param.shape}')\n",
    "        matched_shapes.append((param.detach().numpy().shape==tf_param.shape))\n",
    "        # convert NHWC to NCHW format and copy to change memory layout\n",
    "        #tf_param = np.transpose(tf_param, (3, 2, 0, 1)).copy() if len(tf_param.shape) == 4 else tf_param\n",
    "        #assert tf_param.shape == param.detach().numpy().shape, name\n",
    "\n",
    "        \n",
    "        #param.copy_(torch.tensor(tf_param, requires_grad=True, dtype=param.dtype))\n",
    "print('matched all shapes =',all(matched_shapes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1110.0, 1100.0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(a[0][0][0]),float(a[0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_weights['inferrer/residual_block_2/batch_normalization_1/gamma:0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_weights['inferrer/conv1d/kernel:0'].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i[0] for i in list(r.named_parameters())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([250])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.get_parameter('resnet_blocks.2.bn_activation_2.0.weight').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.49530053, -0.55358905, -0.41502154, ..., -0.07069803,\n",
       "       -0.12090866, -0.12089201], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import \n",
    "np.permue(tf_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein_functions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
