{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "curdir = Path(os.getcwd())\n",
    "sys.path.append(str(curdir.parent.absolute()))\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils.data import read_fasta\n",
    "from src.data.datasets import ProteinDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_fasta('../data/swissprot/proteinfer_splits/random/train_GO.fasta')\n",
    "val = read_fasta('../data/swissprot/proteinfer_splits/random/dev_GO.fasta')\n",
    "test = read_fasta('../data/swissprot/proteinfer_splits/random/test_GO.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [(k[0],j,\" \".join(k[1:])) for j,k in train]\n",
    "test = [(k[0],j,\" \".join(k[1:])) for j,k in test]\n",
    "val = [(k[0],j,\" \".join(k[1:])) for j,k in val]\n",
    "\n",
    "df = train + val + test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df,columns=['id','sequence','labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sequences: 522607\n"
     ]
    }
   ],
   "source": [
    "num_sequences = len(df)\n",
    "print('number of sequences:',num_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Counter()\n",
    "\n",
    "vocab = set()\n",
    "amino_freq = Counter()\n",
    "for idx,row in df.iterrows():\n",
    "    sequence = row['sequence']\n",
    "    row_labels = row['labels']\n",
    "    aa_list = list(sequence)\n",
    "    if row_labels =='':\n",
    "        print(row['id'],row['labels'])\n",
    "    vocab.update(aa_list)\n",
    "    amino_freq.update(aa_list)\n",
    "    labels.update(row_labels.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# GO Terms: 32102\n"
     ]
    }
   ],
   "source": [
    "print('# GO Terms:',len(labels.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO Terms distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     32102.000000\n",
       "mean        777.250545\n",
       "std        9114.786603\n",
       "min           1.000000\n",
       "25%           4.000000\n",
       "50%          17.000000\n",
       "75%          84.000000\n",
       "max      462356.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('GO Terms distribution')\n",
    "pd.Series(labels.values()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    522607.000000\n",
       "mean        368.042215\n",
       "std         334.721845\n",
       "min           2.000000\n",
       "25%         179.000000\n",
       "50%         303.000000\n",
       "75%         456.000000\n",
       "max       35213.000000\n",
       "Name: sequence, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Sequence length distribution')\n",
    "\n",
    "df['sequence'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PD = ProteinDataset(data_path='../data/swissprot/proteinfer_splits/random/train_GO.fasta',\n",
    "                    sequence_vocabulary_path='../data/vocabularies/amino_acid_vocab.json',\n",
    "                    label_vocabulary_path='../data/vocabularies/GO_label_vocab.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seqs_preds = pd.read_csv('../proteinfer/hemoglobin_predictions.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PD.data = [i for i in PD.data if i[1][0] in ['P69891','Q7AP54']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 569)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PD),PD.get_max_seq_len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch num variables: 74\n",
      "Tensorflow num variables: 74\n",
      "\n",
      "\n",
      "conv1.weight:torch.Size([1100, 20, 9]) <--> inferrer/conv1d/kernel:0:(1100, 20, 9)\n",
      "conv1.bias:torch.Size([1100]) <--> inferrer/conv1d/bias:0:(1100,)\n",
      "resnet_blocks.0.bn_activation_1.0.weight:torch.Size([1100]) <--> inferrer/residual_block_0/batch_normalization/gamma:0:(1100,)\n",
      "resnet_blocks.0.bn_activation_1.0.bias:torch.Size([1100]) <--> inferrer/residual_block_0/batch_normalization/beta:0:(1100,)\n",
      "resnet_blocks.0.bn_activation_1.0.running_mean:torch.Size([1100]) <--> inferrer/residual_block_0/batch_normalization/moving_mean:0:(1100,)\n",
      "resnet_blocks.0.bn_activation_1.0.running_var:torch.Size([1100]) <--> inferrer/residual_block_0/batch_normalization/moving_variance:0:(1100,)\n",
      "resnet_blocks.0.bn_activation_1.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_0/batch_normalization/num_batches_tracked:0:()\n",
      "resnet_blocks.0.masked_conv1.weight:torch.Size([550, 1100, 9]) <--> inferrer/residual_block_0/conv1d/kernel:0:(550, 1100, 9)\n",
      "resnet_blocks.0.masked_conv1.bias:torch.Size([550]) <--> inferrer/residual_block_0/conv1d/bias:0:(550,)\n",
      "resnet_blocks.0.bn_activation_2.0.weight:torch.Size([550]) <--> inferrer/residual_block_0/batch_normalization_1/gamma:0:(550,)\n",
      "resnet_blocks.0.bn_activation_2.0.bias:torch.Size([550]) <--> inferrer/residual_block_0/batch_normalization_1/beta:0:(550,)\n",
      "resnet_blocks.0.bn_activation_2.0.running_mean:torch.Size([550]) <--> inferrer/residual_block_0/batch_normalization_1/moving_mean:0:(550,)\n",
      "resnet_blocks.0.bn_activation_2.0.running_var:torch.Size([550]) <--> inferrer/residual_block_0/batch_normalization_1/moving_variance:0:(550,)\n",
      "resnet_blocks.0.bn_activation_2.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_0/batch_normalization_1/num_batches_tracked:0:()\n",
      "resnet_blocks.0.masked_conv2.weight:torch.Size([1100, 550, 1]) <--> inferrer/residual_block_0/conv1d_1/kernel:0:(1100, 550, 1)\n",
      "resnet_blocks.0.masked_conv2.bias:torch.Size([1100]) <--> inferrer/residual_block_0/conv1d_1/bias:0:(1100,)\n",
      "resnet_blocks.1.bn_activation_1.0.weight:torch.Size([1100]) <--> inferrer/residual_block_1/batch_normalization/gamma:0:(1100,)\n",
      "resnet_blocks.1.bn_activation_1.0.bias:torch.Size([1100]) <--> inferrer/residual_block_1/batch_normalization/beta:0:(1100,)\n",
      "resnet_blocks.1.bn_activation_1.0.running_mean:torch.Size([1100]) <--> inferrer/residual_block_1/batch_normalization/moving_mean:0:(1100,)\n",
      "resnet_blocks.1.bn_activation_1.0.running_var:torch.Size([1100]) <--> inferrer/residual_block_1/batch_normalization/moving_variance:0:(1100,)\n",
      "resnet_blocks.1.bn_activation_1.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_1/batch_normalization/num_batches_tracked:0:()\n",
      "resnet_blocks.1.masked_conv1.weight:torch.Size([550, 1100, 9]) <--> inferrer/residual_block_1/conv1d/kernel:0:(550, 1100, 9)\n",
      "resnet_blocks.1.masked_conv1.bias:torch.Size([550]) <--> inferrer/residual_block_1/conv1d/bias:0:(550,)\n",
      "resnet_blocks.1.bn_activation_2.0.weight:torch.Size([550]) <--> inferrer/residual_block_1/batch_normalization_1/gamma:0:(550,)\n",
      "resnet_blocks.1.bn_activation_2.0.bias:torch.Size([550]) <--> inferrer/residual_block_1/batch_normalization_1/beta:0:(550,)\n",
      "resnet_blocks.1.bn_activation_2.0.running_mean:torch.Size([550]) <--> inferrer/residual_block_1/batch_normalization_1/moving_mean:0:(550,)\n",
      "resnet_blocks.1.bn_activation_2.0.running_var:torch.Size([550]) <--> inferrer/residual_block_1/batch_normalization_1/moving_variance:0:(550,)\n",
      "resnet_blocks.1.bn_activation_2.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_1/batch_normalization_1/num_batches_tracked:0:()\n",
      "resnet_blocks.1.masked_conv2.weight:torch.Size([1100, 550, 1]) <--> inferrer/residual_block_1/conv1d_1/kernel:0:(1100, 550, 1)\n",
      "resnet_blocks.1.masked_conv2.bias:torch.Size([1100]) <--> inferrer/residual_block_1/conv1d_1/bias:0:(1100,)\n",
      "resnet_blocks.2.bn_activation_1.0.weight:torch.Size([1100]) <--> inferrer/residual_block_2/batch_normalization/gamma:0:(1100,)\n",
      "resnet_blocks.2.bn_activation_1.0.bias:torch.Size([1100]) <--> inferrer/residual_block_2/batch_normalization/beta:0:(1100,)\n",
      "resnet_blocks.2.bn_activation_1.0.running_mean:torch.Size([1100]) <--> inferrer/residual_block_2/batch_normalization/moving_mean:0:(1100,)\n",
      "resnet_blocks.2.bn_activation_1.0.running_var:torch.Size([1100]) <--> inferrer/residual_block_2/batch_normalization/moving_variance:0:(1100,)\n",
      "resnet_blocks.2.bn_activation_1.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_2/batch_normalization/num_batches_tracked:0:()\n",
      "resnet_blocks.2.masked_conv1.weight:torch.Size([550, 1100, 9]) <--> inferrer/residual_block_2/conv1d/kernel:0:(550, 1100, 9)\n",
      "resnet_blocks.2.masked_conv1.bias:torch.Size([550]) <--> inferrer/residual_block_2/conv1d/bias:0:(550,)\n",
      "resnet_blocks.2.bn_activation_2.0.weight:torch.Size([550]) <--> inferrer/residual_block_2/batch_normalization_1/gamma:0:(550,)\n",
      "resnet_blocks.2.bn_activation_2.0.bias:torch.Size([550]) <--> inferrer/residual_block_2/batch_normalization_1/beta:0:(550,)\n",
      "resnet_blocks.2.bn_activation_2.0.running_mean:torch.Size([550]) <--> inferrer/residual_block_2/batch_normalization_1/moving_mean:0:(550,)\n",
      "resnet_blocks.2.bn_activation_2.0.running_var:torch.Size([550]) <--> inferrer/residual_block_2/batch_normalization_1/moving_variance:0:(550,)\n",
      "resnet_blocks.2.bn_activation_2.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_2/batch_normalization_1/num_batches_tracked:0:()\n",
      "resnet_blocks.2.masked_conv2.weight:torch.Size([1100, 550, 1]) <--> inferrer/residual_block_2/conv1d_1/kernel:0:(1100, 550, 1)\n",
      "resnet_blocks.2.masked_conv2.bias:torch.Size([1100]) <--> inferrer/residual_block_2/conv1d_1/bias:0:(1100,)\n",
      "resnet_blocks.3.bn_activation_1.0.weight:torch.Size([1100]) <--> inferrer/residual_block_3/batch_normalization/gamma:0:(1100,)\n",
      "resnet_blocks.3.bn_activation_1.0.bias:torch.Size([1100]) <--> inferrer/residual_block_3/batch_normalization/beta:0:(1100,)\n",
      "resnet_blocks.3.bn_activation_1.0.running_mean:torch.Size([1100]) <--> inferrer/residual_block_3/batch_normalization/moving_mean:0:(1100,)\n",
      "resnet_blocks.3.bn_activation_1.0.running_var:torch.Size([1100]) <--> inferrer/residual_block_3/batch_normalization/moving_variance:0:(1100,)\n",
      "resnet_blocks.3.bn_activation_1.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_3/batch_normalization/num_batches_tracked:0:()\n",
      "resnet_blocks.3.masked_conv1.weight:torch.Size([550, 1100, 9]) <--> inferrer/residual_block_3/conv1d/kernel:0:(550, 1100, 9)\n",
      "resnet_blocks.3.masked_conv1.bias:torch.Size([550]) <--> inferrer/residual_block_3/conv1d/bias:0:(550,)\n",
      "resnet_blocks.3.bn_activation_2.0.weight:torch.Size([550]) <--> inferrer/residual_block_3/batch_normalization_1/gamma:0:(550,)\n",
      "resnet_blocks.3.bn_activation_2.0.bias:torch.Size([550]) <--> inferrer/residual_block_3/batch_normalization_1/beta:0:(550,)\n",
      "resnet_blocks.3.bn_activation_2.0.running_mean:torch.Size([550]) <--> inferrer/residual_block_3/batch_normalization_1/moving_mean:0:(550,)\n",
      "resnet_blocks.3.bn_activation_2.0.running_var:torch.Size([550]) <--> inferrer/residual_block_3/batch_normalization_1/moving_variance:0:(550,)\n",
      "resnet_blocks.3.bn_activation_2.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_3/batch_normalization_1/num_batches_tracked:0:()\n",
      "resnet_blocks.3.masked_conv2.weight:torch.Size([1100, 550, 1]) <--> inferrer/residual_block_3/conv1d_1/kernel:0:(1100, 550, 1)\n",
      "resnet_blocks.3.masked_conv2.bias:torch.Size([1100]) <--> inferrer/residual_block_3/conv1d_1/bias:0:(1100,)\n",
      "resnet_blocks.4.bn_activation_1.0.weight:torch.Size([1100]) <--> inferrer/residual_block_4/batch_normalization/gamma:0:(1100,)\n",
      "resnet_blocks.4.bn_activation_1.0.bias:torch.Size([1100]) <--> inferrer/residual_block_4/batch_normalization/beta:0:(1100,)\n",
      "resnet_blocks.4.bn_activation_1.0.running_mean:torch.Size([1100]) <--> inferrer/residual_block_4/batch_normalization/moving_mean:0:(1100,)\n",
      "resnet_blocks.4.bn_activation_1.0.running_var:torch.Size([1100]) <--> inferrer/residual_block_4/batch_normalization/moving_variance:0:(1100,)\n",
      "resnet_blocks.4.bn_activation_1.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_4/batch_normalization/num_batches_tracked:0:()\n",
      "resnet_blocks.4.masked_conv1.weight:torch.Size([550, 1100, 9]) <--> inferrer/residual_block_4/conv1d/kernel:0:(550, 1100, 9)\n",
      "resnet_blocks.4.masked_conv1.bias:torch.Size([550]) <--> inferrer/residual_block_4/conv1d/bias:0:(550,)\n",
      "resnet_blocks.4.bn_activation_2.0.weight:torch.Size([550]) <--> inferrer/residual_block_4/batch_normalization_1/gamma:0:(550,)\n",
      "resnet_blocks.4.bn_activation_2.0.bias:torch.Size([550]) <--> inferrer/residual_block_4/batch_normalization_1/beta:0:(550,)\n",
      "resnet_blocks.4.bn_activation_2.0.running_mean:torch.Size([550]) <--> inferrer/residual_block_4/batch_normalization_1/moving_mean:0:(550,)\n",
      "resnet_blocks.4.bn_activation_2.0.running_var:torch.Size([550]) <--> inferrer/residual_block_4/batch_normalization_1/moving_variance:0:(550,)\n",
      "resnet_blocks.4.bn_activation_2.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_4/batch_normalization_1/num_batches_tracked:0:()\n",
      "resnet_blocks.4.masked_conv2.weight:torch.Size([1100, 550, 1]) <--> inferrer/residual_block_4/conv1d_1/kernel:0:(1100, 550, 1)\n",
      "resnet_blocks.4.masked_conv2.bias:torch.Size([1100]) <--> inferrer/residual_block_4/conv1d_1/bias:0:(1100,)\n",
      "output_layer.weight:torch.Size([32102, 1100]) <--> inferrer/logits/kernel:0:(32102, 1100)\n",
      "output_layer.bias:torch.Size([32102]) <--> inferrer/logits/bias:0:(32102,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ProteInfer(\n",
       "  (conv1): MaskedConv1D(20, 1100, kernel_size=(9,), stride=(1,), padding=same)\n",
       "  (resnet_blocks): ModuleList(\n",
       "    (0): Residual(\n",
       "      (bn_activation_1): Sequential(\n",
       "        (0): BatchNorm1d(1100, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv1): MaskedConv1D(1100, 550, kernel_size=(9,), stride=(1,), padding=same)\n",
       "      (bn_activation_2): Sequential(\n",
       "        (0): BatchNorm1d(550, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv2): MaskedConv1D(550, 1100, kernel_size=(1,), stride=(1,), padding=same)\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (bn_activation_1): Sequential(\n",
       "        (0): BatchNorm1d(1100, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv1): MaskedConv1D(1100, 550, kernel_size=(9,), stride=(1,), padding=same, dilation=(3,))\n",
       "      (bn_activation_2): Sequential(\n",
       "        (0): BatchNorm1d(550, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv2): MaskedConv1D(550, 1100, kernel_size=(1,), stride=(1,), padding=same)\n",
       "    )\n",
       "    (2): Residual(\n",
       "      (bn_activation_1): Sequential(\n",
       "        (0): BatchNorm1d(1100, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv1): MaskedConv1D(1100, 550, kernel_size=(9,), stride=(1,), padding=same, dilation=(9,))\n",
       "      (bn_activation_2): Sequential(\n",
       "        (0): BatchNorm1d(550, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv2): MaskedConv1D(550, 1100, kernel_size=(1,), stride=(1,), padding=same)\n",
       "    )\n",
       "    (3): Residual(\n",
       "      (bn_activation_1): Sequential(\n",
       "        (0): BatchNorm1d(1100, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv1): MaskedConv1D(1100, 550, kernel_size=(9,), stride=(1,), padding=same, dilation=(27,))\n",
       "      (bn_activation_2): Sequential(\n",
       "        (0): BatchNorm1d(550, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv2): MaskedConv1D(550, 1100, kernel_size=(1,), stride=(1,), padding=same)\n",
       "    )\n",
       "    (4): Residual(\n",
       "      (bn_activation_1): Sequential(\n",
       "        (0): BatchNorm1d(1100, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv1): MaskedConv1D(1100, 550, kernel_size=(9,), stride=(1,), padding=same, dilation=(81,))\n",
       "      (bn_activation_2): Sequential(\n",
       "        (0): BatchNorm1d(550, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv2): MaskedConv1D(550, 1100, kernel_size=(1,), stride=(1,), padding=same)\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=1100, out_features=32102, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.protein_encoders import ProteInfer\n",
    "import torch\n",
    "model = ProteInfer(num_labels=32102,\n",
    "                      input_channels=20,\n",
    "                      output_channels=1100,\n",
    "                      kernel_size=9,\n",
    "                      activation=torch.nn.ReLU,\n",
    "                      dilation_base=3,\n",
    "                      num_resnet_blocks=5,\n",
    "                      bottleneck_factor=0.5)\n",
    "\n",
    "from src.utils.proteinfer import transfer_tf_weights_to_torch\n",
    "transfer_tf_weights_to_torch(model,'../models/proteinfer/GO_model_weights.pkl')\n",
    "\n",
    "model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.data.collators import collate_variable_sequence_length\n",
    "PD_loader = DataLoader(dataset=PD,\n",
    "                          batch_size=2,\n",
    "                          shuffle=False,\n",
    "                          num_workers=2,\n",
    "                          collate_fn=collate_variable_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 20, 569]) torch.Size([2, 32102]) torch.Size([2])\n",
      "input_seq torch.Size([1, 20, 569]) tensor(0.0129, device='cuda:0') tensor(147., device='cuda:0')\n",
      "input_seq_len torch.Size([2, 32102]) tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (20) must match the size of tensor b (32102) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(i\u001b[39m.\u001b[39mshape,s\u001b[39m.\u001b[39mshape,l\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m i\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mcat((i[\u001b[39m0\u001b[39m],torch\u001b[39m.\u001b[39mzeros((\u001b[39m20\u001b[39m,\u001b[39m0\u001b[39m))),dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m logits \u001b[39m=\u001b[39m model(i\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mFloatTensor)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m'\u001b[39m),s\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      6\u001b[0m probas \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(logits)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(probas)\n",
      "File \u001b[0;32m/anaconda/envs/protein_functions/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ProteinFunctions/src/models/protein_encoders.py:102\u001b[0m, in \u001b[0;36mProteInfer.forward\u001b[0;34m(self, x, sequence_lengths)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minput_seq\u001b[39m\u001b[39m'\u001b[39m,x\u001b[39m.\u001b[39mshape,x\u001b[39m.\u001b[39mmean(),x\u001b[39m.\u001b[39msum())\n\u001b[1;32m    101\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minput_seq_len\u001b[39m\u001b[39m'\u001b[39m,sequence_lengths\u001b[39m.\u001b[39mshape,sequence_lengths)\n\u001b[0;32m--> 102\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x,sequence_lengths)\n\u001b[1;32m    103\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mfirst_conv\u001b[39m\u001b[39m'\u001b[39m,features\u001b[39m.\u001b[39mshape,features\u001b[39m.\u001b[39mmean())\n\u001b[1;32m    104\u001b[0m \u001b[39m#Sequential doesn't work here because of multiple inputs\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/protein_functions/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ProteinFunctions/src/models/protein_encoders.py:12\u001b[0m, in \u001b[0;36mMaskedConv1D.forward\u001b[0;34m(self, x, sequence_lengths)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x,sequence_lengths):\n\u001b[1;32m      8\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m    Correct for padding before and after. Can be redundant\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m    but reduces overhead of setting padding to sentiel in other contexts.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     x \u001b[39m=\u001b[39m set_padding_to_sentinel(x,sequence_lengths,\u001b[39m0\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minput_to_conv\u001b[39m\u001b[39m'\u001b[39m,x\u001b[39m.\u001b[39mshape,x\u001b[39m.\u001b[39mmean(),x\u001b[39m.\u001b[39msum())\n\u001b[1;32m     14\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mforward(x)\n",
      "File \u001b[0;32m~/ProteinFunctions/src/data/datasets.py:79\u001b[0m, in \u001b[0;36mset_padding_to_sentinel\u001b[0;34m(padded_representations, sequence_lengths, sentinel)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_padding_to_sentinel\u001b[39m(padded_representations, sequence_lengths, sentinel):\n\u001b[1;32m     78\u001b[0m     \u001b[39m# Create a sequence mask\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     seq_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(padded_representations\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mto(sequence_lengths\u001b[39m.\u001b[39mdevice) \u001b[39m<\u001b[39m sequence_lengths[:, \u001b[39mNone\u001b[39;00m]\n\u001b[1;32m     81\u001b[0m     \u001b[39m#Sentinel and padded_representations should be same dtype\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     sentinel \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(sentinel, dtype\u001b[39m=\u001b[39mpadded_representations\u001b[39m.\u001b[39mdtype, device\u001b[39m=\u001b[39mpadded_representations\u001b[39m.\u001b[39mdevice)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (20) must match the size of tensor b (32102) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i,l,s in PD_loader:\n",
    "        print(i.shape,s.shape,l.shape)\n",
    "        i=torch.cat((i[0],torch.zeros((20,0))),dim=1).unsqueeze(0)\n",
    "        logits = model(i.type(torch.FloatTensor).to('cuda:0'),s.to('cuda:0'))\n",
    "        probas = torch.sigmoid(logits)\n",
    "        print(probas)\n",
    "        above_th = (probas>0.5)*1\n",
    "        print(above_th.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_seq torch.Size([2, 20, 569]) tensor(0.0315, device='cuda:0') tensor(716., device='cuda:0')\n",
      "input_seq_len torch.Size([2]) tensor([147, 569], device='cuda:0')\n",
      "input_to_conv torch.Size([2, 20, 569]) tensor(0.0315, device='cuda:0') tensor(716., device='cuda:0')\n",
      "output_of_conv torch.Size([2, 1100, 569]) tensor(-1.1537, device='cuda:0') tensor(-1444248.5000, device='cuda:0')\n",
      "tensor([[[-0.7153, -0.6415, -0.3653,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-2.3647,  0.4084, -2.2052,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.2829, -2.3705,  0.3380,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-1.0497, -2.2400, -1.3620,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.3808, -1.9959, -0.6329,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-1.4631, -1.0661, -2.8533,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.9580, -0.7764,  0.2500,  ..., -0.0622, -1.5976, -1.4675],\n",
      "         [-0.0781,  1.4956, -1.2454,  ..., -2.4412, -1.7659, -1.5335],\n",
      "         [-0.6667,  0.2899,  0.2071,  ..., -0.2132, -0.7919, -1.4535],\n",
      "         ...,\n",
      "         [-1.6559, -2.8153, -2.1431,  ..., -1.4204, -0.5961, -1.0655],\n",
      "         [ 0.7937, -0.7854, -1.5563,  ..., -1.4644, -1.0380,  0.1059],\n",
      "         [-1.5065, -2.4892, -4.0855,  ..., -1.3448, -2.0380, -1.1459]]],\n",
      "       device='cuda:0')\n",
      "output_of_sentiel torch.Size([2, 1100, 569]) tensor(-0.9786, device='cuda:0') tensor(-1224965.5000, device='cuda:0')\n",
      "first_conv torch.Size([2, 1100, 569]) tensor(-0.9786, device='cuda:0')\n",
      "resnet_block:  0\n",
      "input_to_conv torch.Size([2, 1100, 569]) tensor(0.0212, device='cuda:0') tensor(26559.7168, device='cuda:0')\n",
      "output_of_conv torch.Size([2, 550, 569]) tensor(-9.1177, device='cuda:0') tensor(-5706797., device='cuda:0')\n",
      "tensor([[[-11.4100,   7.5173, -27.7274,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [ 11.8071,  15.3372,  -9.5157,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [ -9.4190,  -6.7623,  -5.3027,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         ...,\n",
      "         [-14.3596, -31.6018,  -3.6381,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [  0.6588,   1.3053,   4.4121,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-20.3283,   1.0571, -10.8975,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-29.4885,  10.7394, -14.3181,  ..., -28.4820,  -9.6317, -10.3426],\n",
      "         [ -3.1167,   5.6194,   3.4269,  ...,   7.5785,  -7.5729,  -5.7812],\n",
      "         [-26.7547,  -7.2880, -14.2965,  ..., -10.7651, -12.9332, -14.0138],\n",
      "         ...,\n",
      "         [-27.8144, -42.2423,   5.4240,  ...,  -3.5647, -20.2628,  -9.9620],\n",
      "         [ -9.8080, -28.8593,   6.4021,  ..., -21.5475,  -3.5663,  -5.2727],\n",
      "         [-21.3636, -12.9450, -15.7697,  ..., -21.0265,  -7.1048, -10.4534]]],\n",
      "       device='cuda:0')\n",
      "output_of_sentiel torch.Size([2, 550, 569]) tensor(-9.1201, device='cuda:0') tensor(-5708257., device='cuda:0')\n",
      "torch.Size([2, 550, 569]) tensor(-9.1201, device='cuda:0')\n",
      "input_to_conv torch.Size([2, 550, 569]) tensor(0.0046, device='cuda:0') tensor(2873.0093, device='cuda:0')\n",
      "output_of_conv torch.Size([2, 1100, 569]) tensor(-0.2336, device='cuda:0') tensor(-292392.1250, device='cuda:0')\n",
      "tensor([[[-1.2433, -0.0641, -0.6908,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.1022, -0.3570,  0.6254,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.2677,  0.2155,  0.4056,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.2622, -0.2877,  0.0349,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.4248, -0.5811, -0.7152,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.3682, -0.9098, -0.9627,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0253, -1.5709, -0.8684,  ..., -0.8901, -1.9740, -1.9248],\n",
      "         [-0.1406, -1.5426,  1.0487,  ..., -0.4193, -0.0432, -1.3161],\n",
      "         [-0.0605, -0.1452,  0.4853,  ...,  0.6477,  0.7394, -0.2290],\n",
      "         ...,\n",
      "         [-0.1371, -0.8322,  0.0838,  ...,  1.2984,  1.7484,  1.0917],\n",
      "         [-0.8113, -0.3567, -0.9044,  ..., -0.9172, -1.1776, -0.9380],\n",
      "         [-0.7260, -0.6056,  0.9224,  ...,  0.4200,  0.2697, -0.2054]]],\n",
      "       device='cuda:0')\n",
      "output_of_sentiel torch.Size([2, 1100, 569]) tensor(-0.1742, device='cuda:0') tensor(-218120., device='cuda:0')\n",
      "resnet_block:  1\n",
      "input_to_conv torch.Size([2, 1100, 569]) tensor(0.0749, device='cuda:0') tensor(93773.4531, device='cuda:0')\n",
      "output_of_conv torch.Size([2, 550, 569]) tensor(-36.5651, device='cuda:0') tensor(-22886124., device='cuda:0')\n",
      "tensor([[[ -15.6251,  -24.5511,  -18.1203,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [ -67.6344,  -74.3481,  -45.0833,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [  13.5916,    4.7834,   22.1367,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         ...,\n",
      "         [ -13.0685,   -8.5003,  -13.9461,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [ -35.6981,  -35.5970,  -30.5615,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [ -56.0922,  -45.0565,  -30.7672,  ...,    0.0000,    0.0000,\n",
      "             0.0000]],\n",
      "\n",
      "        [[ -27.7576,  -30.5570,  -37.2497,  ...,  -30.2137,  -29.2854,\n",
      "           -38.2116],\n",
      "         [ -79.9583,  -74.6180,  -94.0528,  ...,  -88.8827,  -80.9938,\n",
      "           -60.5577],\n",
      "         [ -59.2990,  -44.6006,  -35.3772,  ...,  -52.4963,  -57.2334,\n",
      "           -63.4695],\n",
      "         ...,\n",
      "         [-135.8989, -130.8549, -124.9812,  ...,  -98.6885, -121.5593,\n",
      "          -101.8896],\n",
      "         [ -33.0273,  -34.0896,  -38.8759,  ...,  -44.6637,  -47.9522,\n",
      "           -40.6984],\n",
      "         [ -24.4442,  -34.9923,  -45.1457,  ...,  -57.7667,  -76.8312,\n",
      "           -67.7265]]], device='cuda:0')\n",
      "output_of_sentiel torch.Size([2, 550, 569]) tensor(-36.3316, device='cuda:0') tensor(-22739960., device='cuda:0')\n",
      "torch.Size([2, 550, 569]) tensor(-36.3316, device='cuda:0')\n",
      "input_to_conv torch.Size([2, 550, 569]) tensor(0.0079, device='cuda:0') tensor(4933.7896, device='cuda:0')\n",
      "output_of_conv torch.Size([2, 1100, 569]) tensor(-0.4649, device='cuda:0') tensor(-581990.1250, device='cuda:0')\n",
      "tensor([[[ 2.1821,  0.4238, -0.4805,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-2.9205, -1.5879, -1.6392,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0771,  0.4391,  0.2552,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-1.9916, -1.2178, -2.8018,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.6151, -1.3033, -2.1520,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-2.6207, -1.4291, -1.4734,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.8472, -3.2337, -1.9514,  ..., -3.5345, -2.3787, -3.4065],\n",
      "         [-0.9354, -0.4368, -0.8908,  ...,  0.5199,  1.2733,  1.1735],\n",
      "         [-0.3104, -1.1147, -0.4161,  ...,  2.9711,  2.3447,  2.1328],\n",
      "         ...,\n",
      "         [-0.5060, -0.7819,  0.2944,  ..., -0.1317,  0.4022,  0.1540],\n",
      "         [-0.8022,  0.5074,  0.4156,  ...,  0.3974,  0.4930,  0.3339],\n",
      "         [-3.5205, -5.4265, -3.3660,  ..., -0.9305, -1.0107, -0.7818]]],\n",
      "       device='cuda:0')\n",
      "output_of_sentiel torch.Size([2, 1100, 569]) tensor(-0.4233, device='cuda:0') tensor(-529876.1875, device='cuda:0')\n",
      "resnet_block:  2\n",
      "input_to_conv torch.Size([2, 1100, 569]) tensor(0.0768, device='cuda:0') tensor(96133.1562, device='cuda:0')\n",
      "output_of_conv torch.Size([2, 550, 569]) tensor(-48.3200, device='cuda:0') tensor(-30243492., device='cuda:0')\n",
      "tensor([[[ -68.8271,  -61.5615,  -59.8585,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [ -72.1789, -103.7472,  -49.5514,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [ -27.3177,  -21.8174,  -32.0579,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         ...,\n",
      "         [ -66.0389,  -74.2000,  -42.7036,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [ -80.7241,  -77.1145,  -87.3601,  ...,    0.0000,    0.0000,\n",
      "             0.0000],\n",
      "         [ -95.1086, -145.8982,  -90.0344,  ...,    0.0000,    0.0000,\n",
      "             0.0000]],\n",
      "\n",
      "        [[-114.3788, -120.3826, -113.3740,  ...,  -18.6888,  -15.2654,\n",
      "           -42.5201],\n",
      "         [-107.5347,  -85.7829,  -59.2484,  ...,  -46.0406,  -64.0213,\n",
      "           -96.9063],\n",
      "         [ -46.3383,  -44.5273,  -40.6807,  ...,  -42.3891,  -55.2892,\n",
      "           -46.5392],\n",
      "         ...,\n",
      "         [ -41.8957,  -71.6399,  -49.9522,  ...,  -41.4601,  -45.9509,\n",
      "           -53.5135],\n",
      "         [ -99.7336,  -87.5446,  -61.7479,  ...,  -91.5562, -108.0313,\n",
      "          -107.5620],\n",
      "         [ -63.2674,  -22.3890,  -40.7906,  ...,  -65.6926,  -91.4895,\n",
      "          -109.3658]]], device='cuda:0')\n",
      "output_of_sentiel torch.Size([2, 550, 569]) tensor(-47.4071, device='cuda:0') tensor(-29672116., device='cuda:0')\n",
      "torch.Size([2, 550, 569]) tensor(-47.4071, device='cuda:0')\n",
      "input_to_conv torch.Size([2, 550, 569]) tensor(0.0087, device='cuda:0') tensor(5428.9697, device='cuda:0')\n",
      "output_of_conv torch.Size([2, 1100, 569]) tensor(-0.3721, device='cuda:0') tensor(-465801., device='cuda:0')\n",
      "tensor([[[-0.3517, -0.4214, -0.0065,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-1.3679, -0.9009, -0.4939,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.7338,  0.3413,  0.3073,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-3.1086, -0.7279, -1.0470,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.1652, -0.8783, -0.2011,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-1.0188, -1.0240, -1.7498,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.4971, -1.4245, -3.2960,  ...,  0.2297, -0.1755, -0.2601],\n",
      "         [-1.0765, -2.8129, -1.8900,  ...,  0.5821,  0.6890, -0.3628],\n",
      "         [ 0.4704,  0.3844,  1.4509,  ...,  3.9204,  3.1626,  4.0457],\n",
      "         ...,\n",
      "         [-0.8838, -0.9593, -1.3577,  ..., -1.3431, -1.5269, -1.9402],\n",
      "         [-0.9783, -1.3706,  0.7757,  ...,  1.2221,  0.8962,  1.3310],\n",
      "         [-1.1496, -1.2650, -1.0699,  ..., -2.5813, -3.3732, -4.0237]]],\n",
      "       device='cuda:0')\n",
      "output_of_sentiel torch.Size([2, 1100, 569]) tensor(-0.3464, device='cuda:0') tensor(-433672.6250, device='cuda:0')\n",
      "resnet_block:  3\n",
      "input_to_conv torch.Size([2, 1100, 569]) tensor(0.0547, device='cuda:0') tensor(68495.3906, device='cuda:0')\n",
      "output_of_conv torch.Size([2, 550, 569]) tensor(-32.7829, device='cuda:0') tensor(-20518794., device='cuda:0')\n",
      "tensor([[[-53.2810, -54.6507, -40.7180,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-47.2317, -19.9663, -31.8802,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-45.9861, -49.9156, -59.9837,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         ...,\n",
      "         [-46.9164, -15.2772, -15.3237,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-73.6009, -57.4942, -63.4040,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-56.7849, -69.2302, -39.9778,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-47.3438, -23.0273, -32.4005,  ..., -36.7073, -28.6994, -39.0986],\n",
      "         [-28.5358, -45.5962, -33.5069,  ..., -28.2612, -24.6344, -23.8633],\n",
      "         [-50.0521, -48.8632, -47.2758,  ..., -28.5003, -19.8544, -29.3618],\n",
      "         ...,\n",
      "         [-49.9626, -31.7441, -40.7582,  ..., -68.6289, -68.8990, -73.5821],\n",
      "         [-52.5868, -48.2401, -51.8152,  ..., -48.6616, -14.9491, -37.3839],\n",
      "         [-61.3192, -64.8575, -73.1969,  ..., -43.0309, -52.7195, -35.7914]]],\n",
      "       device='cuda:0')\n",
      "output_of_sentiel torch.Size([2, 550, 569]) tensor(-30.8888, device='cuda:0') tensor(-19333316., device='cuda:0')\n",
      "torch.Size([2, 550, 569]) tensor(-30.8888, device='cuda:0')\n",
      "input_to_conv torch.Size([2, 550, 569]) tensor(0.0124, device='cuda:0') tensor(7744.1704, device='cuda:0')\n",
      "output_of_conv torch.Size([2, 1100, 569]) tensor(-0.2464, device='cuda:0') tensor(-308494.3125, device='cuda:0')\n",
      "tensor([[[ 0.6250,  0.6678,  2.7005,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.2547,  0.3776,  0.6685,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.5242, -1.0240, -0.5723,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.1768, -0.1833, -0.0799,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.7476, -0.9681,  0.4083,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.1990,  0.7073,  1.6353,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0062, -0.2096,  1.0674,  ...,  1.3984,  0.5221,  0.2204],\n",
      "         [-0.8067,  1.0163, -1.3814,  ...,  0.0979,  0.1094, -1.2027],\n",
      "         [-0.7611,  0.1627,  0.2011,  ..., -0.9142,  0.0883, -0.7916],\n",
      "         ...,\n",
      "         [ 1.0266,  1.7978,  0.9704,  ...,  0.4068,  0.0711,  0.6249],\n",
      "         [ 0.1030, -0.4308,  0.6427,  ...,  1.3761,  1.1114, -0.0163],\n",
      "         [ 0.0316, -1.7764, -1.3619,  ..., -0.1565, -0.3608,  0.2213]]],\n",
      "       device='cuda:0')\n",
      "output_of_sentiel torch.Size([2, 1100, 569]) tensor(-0.2671, device='cuda:0') tensor(-334384.0625, device='cuda:0')\n",
      "resnet_block:  4\n",
      "input_to_conv torch.Size([2, 1100, 569]) tensor(0.0284, device='cuda:0') tensor(35549.7734, device='cuda:0')\n",
      "output_of_conv torch.Size([2, 550, 569]) tensor(-14.6722, device='cuda:0') tensor(-9183332., device='cuda:0')\n",
      "tensor([[[-16.7106, -19.2401, -22.3916,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-15.9925, -17.7781, -18.5345,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-14.3760, -10.8630, -20.8311,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         ...,\n",
      "         [-17.0111, -16.4548, -14.6141,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-14.9625, -13.2513, -10.2514,  ...,   0.0000,   0.0000,   0.0000],\n",
      "         [-14.5270, -15.8451, -18.5561,  ...,   0.0000,   0.0000,   0.0000]],\n",
      "\n",
      "        [[-22.8789, -19.9746, -23.3664,  ...,  -8.1631, -14.2833, -24.0379],\n",
      "         [-31.1333, -24.6104, -19.5687,  ..., -19.7584,  -8.0484, -10.7080],\n",
      "         [-20.2946, -29.5208, -11.8052,  ..., -24.1901, -33.4097, -23.8050],\n",
      "         ...,\n",
      "         [-20.9712, -32.5192, -29.2422,  ..., -22.2330, -16.7516, -19.6137],\n",
      "         [-22.8303, -23.5040, -21.7711,  ..., -17.1360, -16.8753,  -8.7711],\n",
      "         [-22.2875, -19.9981, -14.1275,  ..., -23.3730, -28.0114, -17.4210]]],\n",
      "       device='cuda:0')\n",
      "output_of_sentiel torch.Size([2, 550, 569]) tensor(-12.7322, device='cuda:0') tensor(-7969088.5000, device='cuda:0')\n",
      "torch.Size([2, 550, 569]) tensor(-12.7322, device='cuda:0')\n",
      "input_to_conv torch.Size([2, 550, 569]) tensor(0.0287, device='cuda:0') tensor(17988.6270, device='cuda:0')\n",
      "output_of_conv torch.Size([2, 1100, 569]) tensor(2.4582, device='cuda:0') tensor(3077165.2500, device='cuda:0')\n",
      "tensor([[[ 0.7407,  5.7920,  2.5102,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-1.4269,  1.1449,  2.0826,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 5.4604,  2.3796, -0.0442,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 3.1540,  1.5007,  2.5144,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 2.5973,  2.2280,  1.0932,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 2.3709, -0.0713,  3.5583,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 3.1598,  6.3448,  6.1787,  ...,  5.6998,  2.4666,  6.2291],\n",
      "         [ 5.0943,  2.8561,  1.3206,  ...,  3.9918, 10.4496,  4.7979],\n",
      "         [ 0.0701,  3.9442, -0.6728,  ...,  5.0467,  2.3526,  2.9354],\n",
      "         ...,\n",
      "         [ 2.3485,  3.9578,  0.5445,  ...,  4.4034,  4.8496, -0.1989],\n",
      "         [ 3.0266,  5.1228,  7.0156,  ...,  1.8571,  3.9641,  3.5459],\n",
      "         [ 2.7674,  3.4731,  1.7299,  ...,  2.0176, -1.1660,  1.4494]]],\n",
      "       device='cuda:0')\n",
      "output_of_sentiel torch.Size([2, 1100, 569]) tensor(2.2268, device='cuda:0') tensor(2787514.2500, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i,s,l in PD_loader:\n",
    "        logits = model(i.type(torch.FloatTensor).to('cuda:0'),s.to('cuda:0'))\n",
    "        probas = torch.sigmoid(logits)\n",
    "        above_th = (probas>0.5)*1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "tensor([[[ 1.0752,  0.5794,  1.2520, -2.1861, -0.2771, -0.0278],\n",
      "         [-1.1708, -1.1192,  1.7641, -1.4485,  0.2079,  0.1950],\n",
      "         [-0.1735,  0.4402,  0.4596,  0.0405, -0.7241, -1.0551],\n",
      "         [ 0.7670,  0.4493,  0.6640, -1.3435,  1.2225,  1.1037]],\n",
      "\n",
      "        [[-0.7285, -0.1041, -2.1080, -0.0435,  1.3493, -1.2803],\n",
      "         [-0.3031, -0.3673,  1.9882, -0.7333, -1.7588, -0.4458],\n",
      "         [ 0.5464, -1.3600,  1.8604,  1.1871,  1.8073, -0.2755],\n",
      "         [-1.2164,  0.0813, -1.8185, -0.3479, -0.7302,  0.7456]],\n",
      "\n",
      "        [[ 2.2673,  0.0968,  0.2001,  0.2980, -0.9458, -1.0923],\n",
      "         [-0.5151, -1.9390,  1.6619, -0.1635,  1.0856, -1.2883],\n",
      "         [ 0.0744,  1.0954,  0.6909, -1.9535, -0.0256, -0.5458],\n",
      "         [ 1.5307, -0.1504, -0.6249, -0.0658,  1.0999,  0.8504]]])\n",
      "After:\n",
      "tensor([[[ 1.0752e+00,  5.7935e-01,  1.2520e+00, -2.1861e+00, -9.9900e+02,\n",
      "          -9.9900e+02],\n",
      "         [-1.1708e+00, -1.1192e+00,  1.7641e+00, -1.4485e+00, -9.9900e+02,\n",
      "          -9.9900e+02],\n",
      "         [-1.7347e-01,  4.4023e-01,  4.5959e-01,  4.0542e-02, -9.9900e+02,\n",
      "          -9.9900e+02],\n",
      "         [ 7.6705e-01,  4.4925e-01,  6.6395e-01, -1.3435e+00, -9.9900e+02,\n",
      "          -9.9900e+02]],\n",
      "\n",
      "        [[-7.2846e-01, -1.0411e-01, -2.1080e+00, -4.3461e-02,  1.3493e+00,\n",
      "          -9.9900e+02],\n",
      "         [-3.0306e-01, -3.6735e-01,  1.9882e+00, -7.3331e-01, -1.7588e+00,\n",
      "          -9.9900e+02],\n",
      "         [ 5.4635e-01, -1.3600e+00,  1.8604e+00,  1.1871e+00,  1.8073e+00,\n",
      "          -9.9900e+02],\n",
      "         [-1.2164e+00,  8.1331e-02, -1.8185e+00, -3.4787e-01, -7.3015e-01,\n",
      "          -9.9900e+02]],\n",
      "\n",
      "        [[ 2.2673e+00,  9.6848e-02,  2.0013e-01,  2.9801e-01, -9.4578e-01,\n",
      "          -1.0923e+00],\n",
      "         [-5.1513e-01, -1.9390e+00,  1.6619e+00, -1.6354e-01,  1.0856e+00,\n",
      "          -1.2883e+00],\n",
      "         [ 7.4386e-02,  1.0954e+00,  6.9088e-01, -1.9535e+00, -2.5612e-02,\n",
      "          -5.4579e-01],\n",
      "         [ 1.5307e+00, -1.5042e-01, -6.2494e-01, -6.5846e-02,  1.0999e+00,\n",
      "           8.5043e-01]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def set_padding_to_sentinel(padded_representations, sequence_lengths, sentinel):\n",
    "    \"\"\"\n",
    "    Set the padding values in the input tensor to the sentinel value.\n",
    "    \n",
    "    Parameters:\n",
    "        padded_representations (torch.Tensor): The input tensor of shape (batch_size, dim, max_sequence_length)\n",
    "        sequence_lengths (torch.Tensor): 1D tensor containing original sequence lengths for each sequence in the batch\n",
    "        sentinel (float): The value to set the padding to\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Tensor with padding values set to sentinel\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the shape of the input tensor\n",
    "    batch_size, dim, max_sequence_length = padded_representations.shape\n",
    "    \n",
    "    # Create a mask that identifies padding\n",
    "    mask = torch.arange(max_sequence_length).expand(batch_size, max_sequence_length) >= sequence_lengths.unsqueeze(1)\n",
    "    \n",
    "    # Expand the mask to cover the 'dim' dimension\n",
    "    mask = mask.unsqueeze(1).expand(-1, dim, -1)\n",
    "    \n",
    "    # Use the mask to set the padding values to sentinel\n",
    "    padded_representations[mask] = sentinel\n",
    "    \n",
    "    return padded_representations\n",
    "\n",
    "# Example usage:\n",
    "batch_size = 3\n",
    "dim = 4\n",
    "max_sequence_length = 6\n",
    "padded_representations = torch.randn(batch_size, dim, max_sequence_length)\n",
    "sequence_lengths = torch.tensor([4, 5, 6])\n",
    "sentinel = -999\n",
    "\n",
    "print(\"Before:\")\n",
    "print(padded_representations)\n",
    "\n",
    "print(\"After:\")\n",
    "print(set_padding_to_sentinel(padded_representations, sequence_lengths, sentinel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_mask = torch.arange(padded_representations.size(1), device=sequence_lengths.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 600, 10])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_representations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([147, 569], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
       "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
       "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
       "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
       "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
       "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
       "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
       "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
       "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
       "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
       "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
       "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
       "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
       "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
       "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
       "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
       "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
       "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
       "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
       "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
       "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
       "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
       "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
       "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
       "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
       "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
       "        504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517,\n",
       "        518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531,\n",
       "        532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
       "        546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,\n",
       "        560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573,\n",
       "        574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587,\n",
       "        588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seq_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSequence mask:\u001b[39m\u001b[39m\"\u001b[39m, seq_mask)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seq_mask' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Sequence mask:\", seq_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3871, 0.1797, 0.5165,  ..., 0.6133, 0.4819, 0.7436],\n",
       "         [0.0933, 0.9330, 0.2361,  ..., 0.8017, 0.6164, 0.3758],\n",
       "         [0.5702, 0.9327, 0.9981,  ..., 0.7602, 0.3556, 0.7660],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.2828, 0.1742, 0.1041,  ..., 0.6913, 0.9794, 0.7480],\n",
       "         [0.3496, 0.2316, 0.5343,  ..., 0.2502, 0.8556, 0.7232],\n",
       "         [0.4305, 0.5330, 0.6826,  ..., 0.8251, 0.3763, 0.1209],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_conv torch.Size([2, 1100, 569]) tensor(-0.4546, device='cuda:0')\n",
      "torch.Size([2, 550, 569]) tensor(-4.2635, device='cuda:0')\n",
      "torch.Size([2, 550, 569]) tensor(-19.1667, device='cuda:0')\n",
      "torch.Size([2, 550, 569]) tensor(-26.5519, device='cuda:0')\n",
      "torch.Size([2, 550, 569]) tensor(-21.3674, device='cuda:0')\n",
      "torch.Size([2, 550, 569]) tensor(-9.5727, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i,s,l in PD_loader:\n",
    "        logits = model(i.type(torch.FloatTensor).to('cuda:0'),s.to('cuda:0'))\n",
    "        probas = torch.sigmoid(logits)\n",
    "        above_th = (probas>0.5)*1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv1d(): argument 'padding' (position 5) must be tuple of ints, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m prot_enc \u001b[39m=\u001b[39m ProteInfer(num_labels\u001b[39m=\u001b[39m\u001b[39m32102\u001b[39m,input_channels\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m,output_channels\u001b[39m=\u001b[39m\u001b[39m1100\u001b[39m,kernel_size\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m,activation\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mReLU,dilation_base\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,num_resnet_blocks\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,bottleneck_factor\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[1;32m      6\u001b[0m seqs_lengths \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m80\u001b[39m,\u001b[39m20\u001b[39m,\u001b[39m5\u001b[39m,\u001b[39m100\u001b[39m,\u001b[39m95\u001b[39m,\u001b[39m80\u001b[39m,\u001b[39m20\u001b[39m,\u001b[39m5\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m o\u001b[39m=\u001b[39mprot_enc(i,seqs_lengths)\n\u001b[1;32m      8\u001b[0m o\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m/anaconda/envs/protein_functions38/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/ProteinFunctions/src/models/protein_encoders.py:95\u001b[0m, in \u001b[0;36mProteInfer.forward\u001b[0;34m(self, x, sequence_lengths)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x,sequence_lengths):\n\u001b[0;32m---> 95\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x,sequence_lengths)\n\u001b[1;32m     97\u001b[0m     \u001b[39m#Sequential doesn't work here because of multiple inputs\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[39mfor\u001b[39;00m resnet_block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresnet_blocks:\n",
      "File \u001b[0;32m/anaconda/envs/protein_functions38/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    728\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/ProteinFunctions/src/models/protein_encoders.py:13\u001b[0m, in \u001b[0;36mMaskedConv1D.forward\u001b[0;34m(self, x, sequence_lengths)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mCorrect for padding before and after. Can be redundant\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mbut reduces overhead of setting padding to sentiel in other contexts.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     12\u001b[0m x \u001b[39m=\u001b[39m set_padding_to_sentinel(x,sequence_lengths,\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m x \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mforward(x)\n\u001b[1;32m     14\u001b[0m x \u001b[39m=\u001b[39m set_padding_to_sentinel(x,sequence_lengths,\u001b[39m0\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/anaconda/envs/protein_functions38/lib/python3.8/site-packages/torch/nn/modules/conv.py:258\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    255\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    256\u001b[0m                     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    257\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 258\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    259\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mTypeError\u001b[0m: conv1d(): argument 'padding' (position 5) must be tuple of ints, not str"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.models.protein_encoders import Residual,ProteInfer\n",
    "i=torch.ones((8,20,100))\n",
    "#r=Residual(input_channels=20,kernel_size=9,dilation=9,bottleneck_factor=0.5,activation = torch.nn.ReLU)\n",
    "prot_enc = ProteInfer(num_labels=32102,input_channels=20,output_channels=1100,kernel_size=9,activation=torch.nn.ReLU,dilation_base=3,num_resnet_blocks=5,bottleneck_factor=0.5)\n",
    "seqs_lengths = torch.tensor([80,20,5,100,95,80,20,5])\n",
    "o=prot_enc(i,seqs_lengths)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch num variables: 74\n",
      "Tensorflow num variables: 74\n",
      "\n",
      "\n",
      "conv1.weight:torch.Size([1100, 20, 9]) <--> inferrer/conv1d/kernel:0:(1100, 20, 9)\n",
      "conv1.bias:torch.Size([1100]) <--> inferrer/conv1d/bias:0:(1100,)\n",
      "resnet_blocks.0.bn_activation_1.0.weight:torch.Size([1100]) <--> inferrer/residual_block_0/batch_normalization/gamma:0:(1100,)\n",
      "resnet_blocks.0.bn_activation_1.0.bias:torch.Size([1100]) <--> inferrer/residual_block_0/batch_normalization/beta:0:(1100,)\n",
      "resnet_blocks.0.bn_activation_1.0.running_mean:torch.Size([1100]) <--> inferrer/residual_block_0/batch_normalization/moving_mean:0:(1100,)\n",
      "resnet_blocks.0.bn_activation_1.0.running_var:torch.Size([1100]) <--> inferrer/residual_block_0/batch_normalization/moving_variance:0:(1100,)\n",
      "resnet_blocks.0.bn_activation_1.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_0/batch_normalization/num_batches_tracked:0:()\n",
      "resnet_blocks.0.masked_conv1.weight:torch.Size([550, 1100, 9]) <--> inferrer/residual_block_0/conv1d/kernel:0:(550, 1100, 9)\n",
      "resnet_blocks.0.masked_conv1.bias:torch.Size([550]) <--> inferrer/residual_block_0/conv1d/bias:0:(550,)\n",
      "resnet_blocks.0.bn_activation_2.0.weight:torch.Size([550]) <--> inferrer/residual_block_0/batch_normalization_1/gamma:0:(550,)\n",
      "resnet_blocks.0.bn_activation_2.0.bias:torch.Size([550]) <--> inferrer/residual_block_0/batch_normalization_1/beta:0:(550,)\n",
      "resnet_blocks.0.bn_activation_2.0.running_mean:torch.Size([550]) <--> inferrer/residual_block_0/batch_normalization_1/moving_mean:0:(550,)\n",
      "resnet_blocks.0.bn_activation_2.0.running_var:torch.Size([550]) <--> inferrer/residual_block_0/batch_normalization_1/moving_variance:0:(550,)\n",
      "resnet_blocks.0.bn_activation_2.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_0/batch_normalization_1/num_batches_tracked:0:()\n",
      "resnet_blocks.0.masked_conv2.weight:torch.Size([1100, 550, 1]) <--> inferrer/residual_block_0/conv1d_1/kernel:0:(1100, 550, 1)\n",
      "resnet_blocks.0.masked_conv2.bias:torch.Size([1100]) <--> inferrer/residual_block_0/conv1d_1/bias:0:(1100,)\n",
      "resnet_blocks.1.bn_activation_1.0.weight:torch.Size([1100]) <--> inferrer/residual_block_1/batch_normalization/gamma:0:(1100,)\n",
      "resnet_blocks.1.bn_activation_1.0.bias:torch.Size([1100]) <--> inferrer/residual_block_1/batch_normalization/beta:0:(1100,)\n",
      "resnet_blocks.1.bn_activation_1.0.running_mean:torch.Size([1100]) <--> inferrer/residual_block_1/batch_normalization/moving_mean:0:(1100,)\n",
      "resnet_blocks.1.bn_activation_1.0.running_var:torch.Size([1100]) <--> inferrer/residual_block_1/batch_normalization/moving_variance:0:(1100,)\n",
      "resnet_blocks.1.bn_activation_1.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_1/batch_normalization/num_batches_tracked:0:()\n",
      "resnet_blocks.1.masked_conv1.weight:torch.Size([550, 1100, 9]) <--> inferrer/residual_block_1/conv1d/kernel:0:(550, 1100, 9)\n",
      "resnet_blocks.1.masked_conv1.bias:torch.Size([550]) <--> inferrer/residual_block_1/conv1d/bias:0:(550,)\n",
      "resnet_blocks.1.bn_activation_2.0.weight:torch.Size([550]) <--> inferrer/residual_block_1/batch_normalization_1/gamma:0:(550,)\n",
      "resnet_blocks.1.bn_activation_2.0.bias:torch.Size([550]) <--> inferrer/residual_block_1/batch_normalization_1/beta:0:(550,)\n",
      "resnet_blocks.1.bn_activation_2.0.running_mean:torch.Size([550]) <--> inferrer/residual_block_1/batch_normalization_1/moving_mean:0:(550,)\n",
      "resnet_blocks.1.bn_activation_2.0.running_var:torch.Size([550]) <--> inferrer/residual_block_1/batch_normalization_1/moving_variance:0:(550,)\n",
      "resnet_blocks.1.bn_activation_2.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_1/batch_normalization_1/num_batches_tracked:0:()\n",
      "resnet_blocks.1.masked_conv2.weight:torch.Size([1100, 550, 1]) <--> inferrer/residual_block_1/conv1d_1/kernel:0:(1100, 550, 1)\n",
      "resnet_blocks.1.masked_conv2.bias:torch.Size([1100]) <--> inferrer/residual_block_1/conv1d_1/bias:0:(1100,)\n",
      "resnet_blocks.2.bn_activation_1.0.weight:torch.Size([1100]) <--> inferrer/residual_block_2/batch_normalization/gamma:0:(1100,)\n",
      "resnet_blocks.2.bn_activation_1.0.bias:torch.Size([1100]) <--> inferrer/residual_block_2/batch_normalization/beta:0:(1100,)\n",
      "resnet_blocks.2.bn_activation_1.0.running_mean:torch.Size([1100]) <--> inferrer/residual_block_2/batch_normalization/moving_mean:0:(1100,)\n",
      "resnet_blocks.2.bn_activation_1.0.running_var:torch.Size([1100]) <--> inferrer/residual_block_2/batch_normalization/moving_variance:0:(1100,)\n",
      "resnet_blocks.2.bn_activation_1.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_2/batch_normalization/num_batches_tracked:0:()\n",
      "resnet_blocks.2.masked_conv1.weight:torch.Size([550, 1100, 9]) <--> inferrer/residual_block_2/conv1d/kernel:0:(550, 1100, 9)\n",
      "resnet_blocks.2.masked_conv1.bias:torch.Size([550]) <--> inferrer/residual_block_2/conv1d/bias:0:(550,)\n",
      "resnet_blocks.2.bn_activation_2.0.weight:torch.Size([550]) <--> inferrer/residual_block_2/batch_normalization_1/gamma:0:(550,)\n",
      "resnet_blocks.2.bn_activation_2.0.bias:torch.Size([550]) <--> inferrer/residual_block_2/batch_normalization_1/beta:0:(550,)\n",
      "resnet_blocks.2.bn_activation_2.0.running_mean:torch.Size([550]) <--> inferrer/residual_block_2/batch_normalization_1/moving_mean:0:(550,)\n",
      "resnet_blocks.2.bn_activation_2.0.running_var:torch.Size([550]) <--> inferrer/residual_block_2/batch_normalization_1/moving_variance:0:(550,)\n",
      "resnet_blocks.2.bn_activation_2.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_2/batch_normalization_1/num_batches_tracked:0:()\n",
      "resnet_blocks.2.masked_conv2.weight:torch.Size([1100, 550, 1]) <--> inferrer/residual_block_2/conv1d_1/kernel:0:(1100, 550, 1)\n",
      "resnet_blocks.2.masked_conv2.bias:torch.Size([1100]) <--> inferrer/residual_block_2/conv1d_1/bias:0:(1100,)\n",
      "resnet_blocks.3.bn_activation_1.0.weight:torch.Size([1100]) <--> inferrer/residual_block_3/batch_normalization/gamma:0:(1100,)\n",
      "resnet_blocks.3.bn_activation_1.0.bias:torch.Size([1100]) <--> inferrer/residual_block_3/batch_normalization/beta:0:(1100,)\n",
      "resnet_blocks.3.bn_activation_1.0.running_mean:torch.Size([1100]) <--> inferrer/residual_block_3/batch_normalization/moving_mean:0:(1100,)\n",
      "resnet_blocks.3.bn_activation_1.0.running_var:torch.Size([1100]) <--> inferrer/residual_block_3/batch_normalization/moving_variance:0:(1100,)\n",
      "resnet_blocks.3.bn_activation_1.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_3/batch_normalization/num_batches_tracked:0:()\n",
      "resnet_blocks.3.masked_conv1.weight:torch.Size([550, 1100, 9]) <--> inferrer/residual_block_3/conv1d/kernel:0:(550, 1100, 9)\n",
      "resnet_blocks.3.masked_conv1.bias:torch.Size([550]) <--> inferrer/residual_block_3/conv1d/bias:0:(550,)\n",
      "resnet_blocks.3.bn_activation_2.0.weight:torch.Size([550]) <--> inferrer/residual_block_3/batch_normalization_1/gamma:0:(550,)\n",
      "resnet_blocks.3.bn_activation_2.0.bias:torch.Size([550]) <--> inferrer/residual_block_3/batch_normalization_1/beta:0:(550,)\n",
      "resnet_blocks.3.bn_activation_2.0.running_mean:torch.Size([550]) <--> inferrer/residual_block_3/batch_normalization_1/moving_mean:0:(550,)\n",
      "resnet_blocks.3.bn_activation_2.0.running_var:torch.Size([550]) <--> inferrer/residual_block_3/batch_normalization_1/moving_variance:0:(550,)\n",
      "resnet_blocks.3.bn_activation_2.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_3/batch_normalization_1/num_batches_tracked:0:()\n",
      "resnet_blocks.3.masked_conv2.weight:torch.Size([1100, 550, 1]) <--> inferrer/residual_block_3/conv1d_1/kernel:0:(1100, 550, 1)\n",
      "resnet_blocks.3.masked_conv2.bias:torch.Size([1100]) <--> inferrer/residual_block_3/conv1d_1/bias:0:(1100,)\n",
      "resnet_blocks.4.bn_activation_1.0.weight:torch.Size([1100]) <--> inferrer/residual_block_4/batch_normalization/gamma:0:(1100,)\n",
      "resnet_blocks.4.bn_activation_1.0.bias:torch.Size([1100]) <--> inferrer/residual_block_4/batch_normalization/beta:0:(1100,)\n",
      "resnet_blocks.4.bn_activation_1.0.running_mean:torch.Size([1100]) <--> inferrer/residual_block_4/batch_normalization/moving_mean:0:(1100,)\n",
      "resnet_blocks.4.bn_activation_1.0.running_var:torch.Size([1100]) <--> inferrer/residual_block_4/batch_normalization/moving_variance:0:(1100,)\n",
      "resnet_blocks.4.bn_activation_1.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_4/batch_normalization/num_batches_tracked:0:()\n",
      "resnet_blocks.4.masked_conv1.weight:torch.Size([550, 1100, 9]) <--> inferrer/residual_block_4/conv1d/kernel:0:(550, 1100, 9)\n",
      "resnet_blocks.4.masked_conv1.bias:torch.Size([550]) <--> inferrer/residual_block_4/conv1d/bias:0:(550,)\n",
      "resnet_blocks.4.bn_activation_2.0.weight:torch.Size([550]) <--> inferrer/residual_block_4/batch_normalization_1/gamma:0:(550,)\n",
      "resnet_blocks.4.bn_activation_2.0.bias:torch.Size([550]) <--> inferrer/residual_block_4/batch_normalization_1/beta:0:(550,)\n",
      "resnet_blocks.4.bn_activation_2.0.running_mean:torch.Size([550]) <--> inferrer/residual_block_4/batch_normalization_1/moving_mean:0:(550,)\n",
      "resnet_blocks.4.bn_activation_2.0.running_var:torch.Size([550]) <--> inferrer/residual_block_4/batch_normalization_1/moving_variance:0:(550,)\n",
      "resnet_blocks.4.bn_activation_2.0.num_batches_tracked:torch.Size([]) <--> inferrer/residual_block_4/batch_normalization_1/num_batches_tracked:0:()\n",
      "resnet_blocks.4.masked_conv2.weight:torch.Size([1100, 550, 1]) <--> inferrer/residual_block_4/conv1d_1/kernel:0:(1100, 550, 1)\n",
      "resnet_blocks.4.masked_conv2.bias:torch.Size([1100]) <--> inferrer/residual_block_4/conv1d_1/bias:0:(1100,)\n",
      "output_layer.weight:torch.Size([32102, 1100]) <--> inferrer/logits/kernel:0:(32102, 1100)\n",
      "output_layer.bias:torch.Size([32102]) <--> inferrer/logits/bias:0:(32102,)\n"
     ]
    }
   ],
   "source": [
    "from src.utils.proteinfer import transfer_tf_weights_to_torch\n",
    "transfer_tf_weights_to_torch(prot_enc,'../models/proteinfer/GO_model_weights.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProteInfer(\n",
       "  (conv1): MaskedConv1D(20, 1100, kernel_size=(9,), stride=(1,), padding=same)\n",
       "  (resnet_blocks): ModuleList(\n",
       "    (0): Residual(\n",
       "      (bn_activation_1): Sequential(\n",
       "        (0): BatchNorm1d(1100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv1): MaskedConv1D(1100, 550, kernel_size=(9,), stride=(1,), padding=same)\n",
       "      (bn_activation_2): Sequential(\n",
       "        (0): BatchNorm1d(550, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv2): MaskedConv1D(550, 1100, kernel_size=(1,), stride=(1,), padding=same)\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (bn_activation_1): Sequential(\n",
       "        (0): BatchNorm1d(1100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv1): MaskedConv1D(1100, 550, kernel_size=(9,), stride=(1,), padding=same, dilation=(3,))\n",
       "      (bn_activation_2): Sequential(\n",
       "        (0): BatchNorm1d(550, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv2): MaskedConv1D(550, 1100, kernel_size=(1,), stride=(1,), padding=same)\n",
       "    )\n",
       "    (2): Residual(\n",
       "      (bn_activation_1): Sequential(\n",
       "        (0): BatchNorm1d(1100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv1): MaskedConv1D(1100, 550, kernel_size=(9,), stride=(1,), padding=same, dilation=(9,))\n",
       "      (bn_activation_2): Sequential(\n",
       "        (0): BatchNorm1d(550, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv2): MaskedConv1D(550, 1100, kernel_size=(1,), stride=(1,), padding=same)\n",
       "    )\n",
       "    (3): Residual(\n",
       "      (bn_activation_1): Sequential(\n",
       "        (0): BatchNorm1d(1100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv1): MaskedConv1D(1100, 550, kernel_size=(9,), stride=(1,), padding=same, dilation=(27,))\n",
       "      (bn_activation_2): Sequential(\n",
       "        (0): BatchNorm1d(550, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv2): MaskedConv1D(550, 1100, kernel_size=(1,), stride=(1,), padding=same)\n",
       "    )\n",
       "    (4): Residual(\n",
       "      (bn_activation_1): Sequential(\n",
       "        (0): BatchNorm1d(1100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv1): MaskedConv1D(1100, 550, kernel_size=(9,), stride=(1,), padding=same, dilation=(81,))\n",
       "      (bn_activation_2): Sequential(\n",
       "        (0): BatchNorm1d(550, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (masked_conv2): MaskedConv1D(550, 1100, kernel_size=(1,), stride=(1,), padding=same)\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=1100, out_features=32102, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prot_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein_functions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
