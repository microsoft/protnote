{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/protein_functions_310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pynvml import *\n",
    "\n",
    "curdir = Path(os.getcwd())\n",
    "sys.path.append(str(curdir.parent.absolute()))\n",
    "os.chdir(str(curdir.parent.absolute()))\n",
    "curdir = Path(os.getcwd())\n",
    "\n",
    "from src.utils.data import (\n",
    "    load_model,\n",
    "    seed_everything,\n",
    "    log_gpu_memory_usage\n",
    ")\n",
    "from src.utils.main_utils import get_or_generate_vocabularies,  get_or_generate_label_embeddings, get_or_generate_sequence_embeddings, validate_arguments\n",
    "from src.data.datasets import ProteinDataset, calculate_pos_weight, create_multiple_loaders, calculate_label_weights\n",
    "from src.models.ProTCLTrainer import ProTCLTrainer\n",
    "from src.models.ProTCL import ProTCL\n",
    "from src.models.protein_encoders import ProteInfer\n",
    "from src.utils.evaluation import EvalMetrics\n",
    "from src.utils.models import count_parameters_by_layer, sigmoid_bias_from_prob,load_checkpoint\n",
    "from src.utils.configs import get_setup\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "import torch\n",
    "import wandb\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from src.data.collators import collate_variable_sequence_length\n",
    "import mlflow\n",
    "import loralib as lora\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_weights_v2(label_weights, target):\n",
    "    \"\"\"\n",
    "    Computes the weights for each sample in the batch based on the target labels\n",
    "    using broadcasting.\n",
    "    \n",
    "    Args:\n",
    "        label_weights: torch.tensor of size [no_of_classes] with the weight of each label.\n",
    "        target: torch.tensor of size [batch, no_of_classes].\n",
    "\n",
    "    Returns:\n",
    "        weights_for_samples: torch.tensor of size [batch, no_of_classes].\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure label_weights is a float tensor for correct broadcasting and computation\n",
    "    label_weights = label_weights.float()\n",
    "\n",
    "    # Multiply weights with target labels using broadcasting\n",
    "    # This step applies the specific class weights to the corresponding labels in the target.\n",
    "    weighted_targets = label_weights * target\n",
    "\n",
    "    # Sum the weighted targets along the class dimension to get a single weight per sample\n",
    "    weights_for_samples = weighted_targets.sum(dim=1, keepdim=True)\n",
    "\n",
    "    # Use broadcasting again for expanding weights across the class dimension\n",
    "    # No need to repeat the tensor explicitly.\n",
    "    weights_for_samples = weights_for_samples.expand_as(target)\n",
    "\n",
    "    return weights_for_samples\n",
    "\n",
    "\n",
    "class CBLoss(torch.nn.Module):\n",
    "    def __init__(self, label_weights, beta=0.99):\n",
    "        super().__init__()\n",
    "\n",
    "        self.label_weights = label_weights\n",
    "        self.beta=beta\n",
    "\n",
    "    def forward(self, input,target):\n",
    "        no_of_classes = len(self.label_weights)\n",
    "        effective_num = 1.0 - torch.pow(self.beta, self.label_weights)\n",
    "\n",
    "        # Replace zeros in effective_num with 'inf' (infinity) to avoid division by zero\n",
    "        effective_num = torch.where(effective_num == 0, torch.tensor(float('inf')), effective_num)\n",
    "\n",
    "        weights = (1.0 - self.beta) / effective_num\n",
    "        weights = weights / torch.sum(weights) * no_of_classes\n",
    "\n",
    "        weights = get_batch_weights_v2(weights,target)\n",
    "\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def CB_loss(labels_one_hot, samples_per_cls, no_of_classes,  beta=0.99):\n",
    "    \"\"\"Compute the Class Balanced Loss between `logits` and the ground truth `labels`.\n",
    "\n",
    "    Class Balanced Loss: ((1-beta)/(1-beta^n))*Loss(labels, logits)\n",
    "    where Loss is one of the standard losses used for Neural Networks.\n",
    "\n",
    "    Args:\n",
    "      labels: A int tensor of size [batch].\n",
    "      logits: A float tensor of size [batch, no_of_classes].\n",
    "      samples_per_cls: A python list of size [no_of_classes].\n",
    "      no_of_classes: total number of classes. int\n",
    "      loss_type: string. One of \"sigmoid\", \"focal\", \"softmax\".\n",
    "      beta: float. Hyperparameter for Class balanced loss.\n",
    "      gamma: float. Hyperparameter for Focal loss.\n",
    "\n",
    "    Returns:\n",
    "      cb_loss: A float tensor representing class balanced loss\n",
    "    \"\"\"\n",
    "    effective_num = 1.0 - np.power(beta, samples_per_cls)\n",
    "    weights = (1.0 - beta) / np.array(effective_num)\n",
    "    weights = weights / np.sum(weights) * no_of_classes\n",
    "\n",
    "\n",
    "    weights = torch.tensor(weights).float()\n",
    "    weights = weights.unsqueeze(0)\n",
    "    weights = weights.repeat(labels_one_hot.shape[0],1) * labels_one_hot\n",
    "    weights = weights.sum(1)\n",
    "    weights = weights.unsqueeze(1)\n",
    "    weights = weights.repeat(1,no_of_classes)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (torch.rand(size=(10,100))>0.4)*1.0\n",
    "preds = torch.rand(size=labels.shape)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_cls = labels.sum(axis=0\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7., 6., 6., 6., 4., 7., 6., 6., 6., 7., 6., 6., 6., 2., 7., 6., 4., 5.,\n",
       "        7., 5., 7., 7., 6., 4., 7., 5., 5., 7., 5., 8., 6., 6., 6., 5., 5., 6.,\n",
       "        5., 7., 3., 5., 4., 7., 5., 4., 5., 8., 7., 1., 7., 6., 6., 6., 5., 5.,\n",
       "        6., 5., 6., 9., 5., 6., 9., 6., 4., 6., 7., 6., 6., 7., 4., 5., 5., 5.,\n",
       "        8., 6., 7., 6., 6., 7., 4., 8., 5., 4., 7., 2., 6., 5., 6., 6., 6., 4.,\n",
       "        5., 7., 7., 9., 6., 7., 8., 8., 3., 6.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_per_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_original = CB_loss(labels, samples_per_cls, len(samples_per_cls),  beta=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(53.7565), tensor(53756.4570))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_original.mean(),w_original.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb=CBLoss(samples_per_cls,beta=0.9)\n",
    "w_mine=cb(None,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(53.7565), tensor(53756.4609))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_mine.mean(),w_mine.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_mine = CB_loss(labels, samples_per_cls, len(samples_per_cls),  beta=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz=3\n",
    "features = torch.randint(0,10,(bsz,2,1))\n",
    "labels = torch.Tensor([1,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature=0.07\n",
    "contrast_mode='all'\n",
    "base_temperature=0.07\n",
    "\n",
    "device = (torch.device('cuda')\n",
    "            if features.is_cuda\n",
    "            else torch.device('cpu'))\n",
    "\n",
    "features = features.view(features.shape[0], features.shape[1], -1)\n",
    "\n",
    "batch_size = features.shape[0]\n",
    "labels = labels.contiguous().view(-1, 1)\n",
    "if labels.shape[0] != batch_size:\n",
    "    raise ValueError('Num of labels does not match num of features')\n",
    "mask = torch.eq(labels, labels.T).float().to(device)\n",
    "\n",
    "\n",
    "contrast_count = features.shape[1]\n",
    "contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "if contrast_mode == 'one':\n",
    "    anchor_feature = features[:, 0]\n",
    "    anchor_count = 1\n",
    "elif contrast_mode == 'all':\n",
    "    anchor_feature = contrast_feature\n",
    "    anchor_count = contrast_count\n",
    "else:\n",
    "    raise ValueError('Unknown mode: {}'.format(contrast_mode))\n",
    "\n",
    "# compute logits\n",
    "anchor_dot_contrast = torch.div(\n",
    "    torch.matmul(anchor_feature, contrast_feature.T),\n",
    "    temperature)\n",
    "# for numerical stability\n",
    "logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "# tile mask\n",
    "mask = mask.repeat(anchor_count, contrast_count)\n",
    "# mask-out self-contrast cases\n",
    "logits_mask = torch.scatter(\n",
    "    torch.ones_like(mask),\n",
    "    1,\n",
    "    torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "    0\n",
    ")\n",
    "mask = mask * logits_mask\n",
    "\n",
    "# compute log_prob\n",
    "exp_logits = torch.exp(logits) * logits_mask\n",
    "log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "\n",
    "# compute mean of log-likelihood over positive\n",
    "mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n",
    "\n",
    "# loss\n",
    "loss = - (temperature / base_temperature) * mean_log_prob_pos\n",
    "\n",
    "loss = loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 1.],\n",
       "        [1., 1., 0., 1., 1., 1.],\n",
       "        [1., 1., 1., 0., 1., 1.],\n",
       "        [1., 1., 1., 1., 0., 1.],\n",
       "        [1., 1., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -573.2203,    -1.7918,  -716.0775,  -716.0775,  -916.0775, -1144.6489])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mask * log_prob).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(126.7857), tensor(126.7857))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.view(anchor_count, batch_size).mean(),loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.view(anchor_count, batch_size).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "del anchor_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_multihot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/samirchar/ProteinFunctions/notebooks/debugging copy.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbastion_tunnel/home/samirchar/ProteinFunctions/notebooks/debugging%20copy.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m log_prob \u001b[39m=\u001b[39m logits \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39mlog(exp_logits\u001b[39m.\u001b[39msum(\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbastion_tunnel/home/samirchar/ProteinFunctions/notebooks/debugging%20copy.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# compute mean of log-likelihood over positive\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bbastion_tunnel/home/samirchar/ProteinFunctions/notebooks/debugging%20copy.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m mean_log_prob_pos \u001b[39m=\u001b[39m (labels_multihot \u001b[39m*\u001b[39m log_prob)\u001b[39m.\u001b[39msum(\u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m mask\u001b[39m.\u001b[39msum(\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbastion_tunnel/home/samirchar/ProteinFunctions/notebooks/debugging%20copy.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbastion_tunnel/home/samirchar/ProteinFunctions/notebooks/debugging%20copy.ipynb#Y112sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m (temperature \u001b[39m/\u001b[39m base_temperature) \u001b[39m*\u001b[39m mean_log_prob_pos\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels_multihot' is not defined"
     ]
    }
   ],
   "source": [
    "temperature=0.07\n",
    "base_temperature=0.07\n",
    "\n",
    "# compute logits\n",
    "anchor_dot_contrast = torch.div(anchor_dot_contrast,temperature)\n",
    "# for numerical stability\n",
    "logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "# compute log_prob\n",
    "exp_logits = torch.exp(logits) \n",
    "log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "\n",
    "# compute mean of log-likelihood over positive\n",
    "mean_log_prob_pos = (labels_multihot * log_prob).sum(1) / labels_multihot.sum(1)\n",
    "\n",
    "# loss\n",
    "loss = - (temperature / base_temperature) * mean_log_prob_pos\n",
    "loss = loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(88.9891)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7918],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logsumexp(logits,dim=1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -1.7918,   -1.7918,   -1.7918,   -1.7918,   -1.7918,   -1.7918],\n",
       "        [-214.2857,  -85.7143,  -42.8571, -128.5714, -128.5714,    0.0000],\n",
       "        [-285.7143, -114.2857,  -57.1429, -171.4286, -171.4286,    0.0000],\n",
       "        [-142.8571,  -57.1429,  -28.5714,  -85.7143,  -85.7143,    0.0000],\n",
       "        [-142.8571,  -57.1429,  -28.5714,  -85.7143,  -85.7143,    0.0000],\n",
       "        [-357.1429, -142.8571,  -71.4286, -214.2857, -214.2857,    0.0000]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000, 128.5714, 171.4286,  85.7143,  85.7143, 214.2857],\n",
       "        [  0.0000, 171.4286, 228.5714, 114.2857, 114.2857, 285.7143],\n",
       "        [  0.0000,  85.7143, 114.2857,  57.1429,  57.1429, 142.8571],\n",
       "        [  0.0000,  85.7143, 114.2857,  57.1429,  57.1429, 142.8571],\n",
       "        [  0.0000, 214.2857, 285.7143, 142.8571, 142.8571, 357.1429]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_dot_contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0],\n",
       "         [2]],\n",
       "\n",
       "        [[3],\n",
       "         [2]],\n",
       "\n",
       "        [[4],\n",
       "         [5]]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [3],\n",
       "        [4],\n",
       "        [2],\n",
       "        [2],\n",
       "        [5]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrast_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  71.4286,  157.1429,  342.8571,  128.5714],\n",
       "        [ 157.1429,  371.4286,  685.7143,  214.2857],\n",
       "        [ 342.8571,  685.7143, 1828.5714,  800.0000],\n",
       "        [ 128.5714,  214.2857,  800.0000,  414.2857]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_dot_contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=MLP(1000,[10,10],bias=False,norm_layer=torch.nn.BatchNorm1d,activation_layer=torch.nn.Identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e=torch.nn.Embedding(100,3)\n",
    "\n",
    "e(torch.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 4.1412e-01,  2.0729e+00,  3.3877e-01],\n",
       "        [ 7.4035e-01, -1.0129e+00,  1.0684e+00],\n",
       "        [-7.6563e-01, -1.6943e-01, -7.2646e-01],\n",
       "        [ 3.0629e-01, -5.6680e-01,  6.6975e-01],\n",
       "        [-4.6175e-03, -4.8004e-01,  1.1684e+00],\n",
       "        [-1.5192e-01,  4.9175e-01, -1.0614e+00],\n",
       "        [-1.7002e-01,  1.8095e-01,  4.0745e-01],\n",
       "        [-1.0855e+00,  1.6527e+00,  1.1391e+00],\n",
       "        [ 7.1451e-01,  2.7505e+00,  5.0293e-01],\n",
       "        [-7.2259e-01, -6.9784e-01,  6.9926e-01],\n",
       "        [-8.0408e-01, -1.9509e+00,  1.9277e+00],\n",
       "        [-1.6251e-01, -1.7948e-01,  6.0711e-01],\n",
       "        [ 1.4911e-01,  3.4602e-01, -1.4749e+00],\n",
       "        [-1.1428e-01,  4.2197e-01, -1.1637e+00],\n",
       "        [-6.9847e-01,  1.1591e+00,  1.7230e-01],\n",
       "        [-4.1416e-01, -1.2346e+00, -1.1913e+00],\n",
       "        [-4.8150e-01,  1.1232e+00,  2.1309e+00],\n",
       "        [ 4.2791e-01,  2.0048e+00,  1.1230e+00],\n",
       "        [ 2.1412e-01,  9.4107e-01, -3.6250e-01],\n",
       "        [ 3.0476e-01, -2.9366e-02,  7.1577e-01],\n",
       "        [ 1.1111e+00,  3.2859e+00, -3.8700e-01],\n",
       "        [-2.6780e-01,  4.5223e-01, -1.5561e+00],\n",
       "        [ 1.7492e+00, -1.2961e+00,  6.7495e-01],\n",
       "        [-1.9354e-01, -1.4452e+00,  7.4329e-01],\n",
       "        [-2.3749e-01, -1.4156e+00,  5.3666e-01],\n",
       "        [ 2.0051e-01,  7.0806e-01, -1.2866e+00],\n",
       "        [ 1.2120e+00, -9.9553e-02, -8.1010e-01],\n",
       "        [-6.4451e-01, -2.9391e-01,  6.8143e-01],\n",
       "        [ 8.9433e-02,  3.1906e-02, -2.2157e-01],\n",
       "        [-6.5695e-01, -2.8275e-01, -1.1841e+00],\n",
       "        [ 3.1109e-01, -7.3270e-02,  1.4882e+00],\n",
       "        [-2.3157e-01,  9.7753e-01, -1.1180e+00],\n",
       "        [ 4.2236e-01,  2.6887e-02, -5.6748e-02],\n",
       "        [-1.1166e+00, -7.5366e-01,  5.2445e-01],\n",
       "        [-7.4717e-01, -2.8172e+00,  1.5306e+00],\n",
       "        [ 2.3401e-01,  2.4709e-01, -5.5698e-01],\n",
       "        [ 5.8064e-02,  2.1018e-01, -1.2149e+00],\n",
       "        [ 2.8053e-01,  6.0376e-01, -2.9387e-01],\n",
       "        [-1.4951e+00,  1.0801e+00,  7.2832e-01],\n",
       "        [ 1.5595e-01, -1.3675e+00, -1.4642e-01],\n",
       "        [-1.2973e-01, -9.1049e-01, -4.4614e-01],\n",
       "        [ 2.3575e-03, -4.3549e-01, -4.4367e-01],\n",
       "        [-3.2981e-01, -6.9884e-01, -1.2228e+00],\n",
       "        [-1.0822e+00, -5.2295e-01,  5.4517e-01],\n",
       "        [ 6.9984e-01,  1.0657e-01,  6.3149e-01],\n",
       "        [-7.8317e-01,  8.6421e-01, -1.1066e+00],\n",
       "        [-5.2400e-01, -7.0290e-01,  1.3407e+00],\n",
       "        [ 3.5794e-01,  1.5427e+00, -2.6545e+00],\n",
       "        [-5.8823e-01, -3.9011e-01, -2.1362e-01],\n",
       "        [ 2.8433e-01, -2.6775e-01, -1.8570e-01],\n",
       "        [ 9.2063e-01,  8.1245e-01,  1.0596e-01],\n",
       "        [ 4.9543e-01,  2.5520e-02,  7.2264e-01],\n",
       "        [-1.5956e+00,  2.1024e+00,  2.3348e+00],\n",
       "        [ 5.0753e-02,  4.4679e-01,  1.1090e+00],\n",
       "        [ 3.6281e-01,  1.5246e+00, -6.1091e-01],\n",
       "        [-2.0431e-03, -3.3988e-01,  5.0113e-01],\n",
       "        [ 3.6552e-01,  1.6496e+00,  1.3314e-01],\n",
       "        [-2.4609e-01, -6.5868e-01,  1.9157e-01],\n",
       "        [-1.1504e+00, -8.1888e-01,  4.3923e-01],\n",
       "        [ 4.3039e-01,  7.1507e-02, -3.7653e-01],\n",
       "        [-1.0791e+00, -2.4048e-01,  4.2345e-01],\n",
       "        [ 1.9567e+00,  2.2771e-01, -1.5723e-01],\n",
       "        [ 4.9176e-01,  8.1366e-01, -7.2535e-01],\n",
       "        [-2.6337e-01,  4.0416e-02, -5.9337e-01],\n",
       "        [ 3.0209e-01,  2.1540e-01, -4.7287e-01],\n",
       "        [-1.0621e+00,  1.6018e+00, -7.7593e-01],\n",
       "        [ 2.1298e-02,  4.7223e-01, -1.9026e-01],\n",
       "        [ 8.6005e-01,  9.4706e-01,  7.5838e-01],\n",
       "        [-6.0646e-01, -3.9555e-01,  8.4763e-01],\n",
       "        [-8.4835e-01,  6.0907e-01,  1.5922e+00],\n",
       "        [ 4.8856e-01,  1.0006e+00, -1.4859e-01],\n",
       "        [ 4.2223e-01, -1.4388e+00, -1.0208e+00],\n",
       "        [ 1.0276e+00, -1.3861e+00, -4.3115e-01],\n",
       "        [-1.0761e-02, -9.9919e-02,  8.8677e-01],\n",
       "        [ 3.9599e-01, -6.0225e-01, -1.0776e+00],\n",
       "        [ 5.0202e-01, -3.1856e-01,  1.5525e+00],\n",
       "        [-6.3705e-01, -9.2683e-01, -7.6245e-01],\n",
       "        [ 9.3045e-01, -9.2651e-01,  3.0462e-02],\n",
       "        [-1.1075e+00,  1.3727e+00, -2.0777e-01],\n",
       "        [ 1.5397e+00,  2.7782e-01, -2.4375e-01],\n",
       "        [ 6.1954e-01,  3.7248e-01,  1.3380e+00],\n",
       "        [-1.6130e-01,  5.3568e-01,  1.9587e+00],\n",
       "        [-1.8537e+00, -1.1964e-01, -6.6178e-01],\n",
       "        [ 1.4381e+00,  4.4171e-01,  1.7309e+00],\n",
       "        [ 1.8737e+00, -2.3101e-01,  5.5219e-01],\n",
       "        [ 8.4100e-02, -7.0921e-01,  6.6169e-01],\n",
       "        [-8.8450e-01,  1.0118e+00, -1.0265e-01],\n",
       "        [ 7.7554e-01, -6.7150e-01,  6.8879e-01],\n",
       "        [-2.2528e+00,  4.5865e-02,  2.2675e-01],\n",
       "        [-7.1048e-01,  1.5160e+00, -3.9299e-01],\n",
       "        [ 1.7056e-01, -2.1750e-01, -1.9245e-01],\n",
       "        [-1.6822e+00, -4.4930e-01,  1.4788e+00],\n",
       "        [ 2.4178e+00,  1.7688e+00, -6.7901e-01],\n",
       "        [ 1.9154e+00,  5.7157e-01,  1.5687e+00],\n",
       "        [-2.1726e+00, -1.4869e+00, -1.2950e+00],\n",
       "        [ 7.0746e-01,  1.3852e+00, -3.9818e-01],\n",
       "        [-2.6641e-01, -2.3976e+00, -6.6122e-01],\n",
       "        [-2.9886e-01, -1.4048e-01, -1.0224e-01],\n",
       "        [-7.1825e-01, -3.1057e-01, -1.4953e+00],\n",
       "        [ 2.6664e-01,  1.0835e+00,  7.4522e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4141,  2.0729,  0.3388],\n",
       "        [ 0.7403, -1.0129,  1.0684],\n",
       "        [-0.7656, -0.1694, -0.7265],\n",
       "        [ 0.3063, -0.5668,  0.6697],\n",
       "        [-0.0046, -0.4800,  1.1684],\n",
       "        [-0.1519,  0.4917, -1.0614],\n",
       "        [-0.1700,  0.1810,  0.4074],\n",
       "        [-1.0855,  1.6527,  1.1391],\n",
       "        [ 0.7145,  2.7505,  0.5029],\n",
       "        [-0.7226, -0.6978,  0.6993]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-25 03:45:01 PST INFO Logging to ./outputs/logs/2023-11-25_03-45-01_Test.log and console...\n",
      "2023-11-25 03:45:01 PST INFO Using device: cuda:0\n",
      "2023-11-25 03:45:01 PST INFO {\n",
      "    \"TRAIN_BATCH_SIZE\": 64,\n",
      "    \"VALIDATION_BATCH_SIZE\": 64,\n",
      "    \"TEST_BATCH_SIZE\": 64,\n",
      "    \"IN_BATCH_SAMPLING\": false,\n",
      "    \"TRAIN_LABEL_SAMPLE_SIZE\": null,\n",
      "    \"VALIDATION_LABEL_SAMPLE_SIZE\": null,\n",
      "    \"LABEL_BATCH_SIZE_LIMIT_NO_GRAD\": 1500,\n",
      "    \"SEQUENCE_BATCH_SIZE_LIMIT_NO_GRAD\": 128,\n",
      "    \"LEARNING_RATE\": 0.001,\n",
      "    \"OPTIMIZER\": \"Adam\",\n",
      "    \"PROTEIN_EMBEDDING_DIM\": 1100,\n",
      "    \"LABEL_EMBEDDING_DIM\": 1024,\n",
      "    \"LATENT_EMBEDDING_DIM\": 1024,\n",
      "    \"OUTPUT_MLP_HIDDEN_DIM_SCALE_FACTOR\": 1,\n",
      "    \"OUTPUT_MLP_NUM_LAYERS\": 2,\n",
      "    \"OUTPUT_NEURON_PROBABILITY_BIAS\": null,\n",
      "    \"OUTPUT_MLP_BATCHNORM\": true,\n",
      "    \"OPTIMIZATION_METRIC_NAME\": \"map_micro\",\n",
      "    \"DECISION_TH_METRIC_NAME\": \"f1_micro\",\n",
      "    \"NUM_EPOCHS\": 15,\n",
      "    \"GRADIENT_ACCUMULATION_STEPS\": 1,\n",
      "    \"GRADIENT_CHECKPOINTING\": false,\n",
      "    \"LORA\": false,\n",
      "    \"LORA_RANK\": 8,\n",
      "    \"CLIP_VALUE\": 1,\n",
      "    \"LOSS_FN\": \"WeightedBCE\",\n",
      "    \"FOCAL_LOSS_GAMMA\": 2,\n",
      "    \"FOCAL_LOSS_ALPHA\": -1,\n",
      "    \"BCE_POS_WEIGHT\": 1,\n",
      "    \"RGDBCE_TEMP\": 0.12,\n",
      "    \"TRAIN_SEQUENCE_ENCODER\": false,\n",
      "    \"TRAIN_LABEL_ENCODER\": false,\n",
      "    \"DISTRIBUTE_LABELS\": false,\n",
      "    \"TRAIN_PROJECTION_HEAD\": true,\n",
      "    \"LABEL_ENCODER_CHECKPOINT\": \"microsoft/biogpt\",\n",
      "    \"DEDUPLICATE\": true,\n",
      "    \"NORMALIZE_PROBABILITIES\": false,\n",
      "    \"SEED\": 42,\n",
      "    \"VALIDATIONS_PER_EPOCH\": 100,\n",
      "    \"NUM_WORKERS\": 4,\n",
      "    \"DECISION_TH\": null,\n",
      "    \"TRAIN_SUBSET_FRACTION\": 1,\n",
      "    \"VALIDATION_SUBSET_FRACTION\": 1,\n",
      "    \"TEST_SUBSET_FRACTION\": 1,\n",
      "    \"SHUFFLE_LABELS\": true\n",
      "}\n",
      "2023-11-25 03:45:05 PST INFO Loaded amino_acid_vocab vocabulary from ./data/vocabularies/proteinfer/amino_acid_vocab.json\n",
      "2023-11-25 03:45:05 PST INFO Loaded GO_label_vocab vocabulary from ./data/vocabularies/proteinfer/GO_label_vocab.json\n",
      "2023-11-25 03:45:05 PST INFO Loaded sequence_id_vocab vocabulary from ./data/vocabularies/proteinfer/sequence_id_vocab.json\n",
      "2023-11-25 03:45:11 PST INFO Removing 66586 duplicate sequences from ./data/swissprot/proteinfer_splits/random/train_GO.fasta...\n",
      "2023-11-25 03:45:24 PST INFO Loaded label embeddings from ./data/None\n",
      "2023-11-25 03:45:25 PST INFO Removing 8479 duplicate sequences from ./data/swissprot/proteinfer_splits/random/dev_GO.fasta...\n",
      "2023-11-25 03:45:36 PST INFO Loaded label embeddings from ./data/None\n",
      "2023-11-25 03:45:37 PST INFO Removing 8176 duplicate sequences from ./data/swissprot/proteinfer_splits/random/test_GO.fasta...\n",
      "2023-11-25 03:45:48 PST INFO Loaded label embeddings from ./data/None\n",
      "2023-11-25 03:45:48 PST INFO ################## 2023-11-25_03-45-01 RUNNING main.py ##################\n",
      "2023-11-25 03:45:49 PST INFO Loaded sequence embeddings from ./data/embeddings/frozen_proteinfer_sequence_embeddings.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f639c7977c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### SETUP ###\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Check if master process\n",
    "is_master = True\n",
    "config = \"configs/base_config.yaml\"\n",
    "name = \"Test\"\n",
    "train_path_name = \"TRAIN_DATA_PATH\"\n",
    "validation_path_name = \"VAL_DATA_PATH\"\n",
    "test_paths_names = [\"TEST_DATA_PATH\"]\n",
    "amlt = False\n",
    "gpu=0\n",
    "rank=0\n",
    "\n",
    "# Unpack and process the config file\n",
    "config = get_setup(\n",
    "    config_path=config,\n",
    "    run_name=name,\n",
    "    overrides=[],\n",
    "    train_path_name=train_path_name,\n",
    "    val_path_name=validation_path_name,\n",
    "    test_paths_names=test_paths_names,\n",
    "    amlt=amlt,\n",
    "    is_master=is_master,\n",
    ")\n",
    "params, paths, timestamp, logger = config[\"params\"], config[\n",
    "    \"paths\"], config[\"timestamp\"], config[\"logger\"]\n",
    "\n",
    "# Set the GPU device, if using\n",
    "torch.cuda.set_device(gpu)\n",
    "device = torch.device('cuda:' + str(gpu)\n",
    "                        if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# Log the params\n",
    "logger.info(json.dumps(params, indent=4))\n",
    "\n",
    "# Initialize label tokenizer\n",
    "label_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    params['LABEL_ENCODER_CHECKPOINT'],\n",
    ")\n",
    "\n",
    "# Initialize label encoder\n",
    "label_encoder = AutoModel.from_pretrained(\n",
    "    params['LABEL_ENCODER_CHECKPOINT'],\n",
    ")\n",
    "if params[\"GRADIENT_CHECKPOINTING\"]:\n",
    "    raise NotImplementedError(\n",
    "        \"Gradient checkpointing is not yet implemented.\")\n",
    "\n",
    "if params[\"LORA\"]:\n",
    "    for layer in label_encoder.layers:\n",
    "        in_features, out_features = 1024, 1024\n",
    "        layer.self_attn.q_proj = lora.Linear(\n",
    "            in_features, out_features, r=params[\"LORA_RANK\"])\n",
    "        layer.self_attn.v_proj = lora.Linear(\n",
    "            in_features, out_features, r=params[\"LORA_RANK\"])\n",
    "        layer.self_attn.k_proj = lora.Linear(\n",
    "            in_features, out_features, r=params[\"LORA_RANK\"])\n",
    "        layer.self_attn.out_proj = lora.Linear(\n",
    "            in_features, out_features, r=params[\"LORA_RANK\"])\n",
    "    # Mark only the LoRA parameters as trainable\n",
    "    lora.mark_only_lora_as_trainable(label_encoder)\n",
    "\n",
    "label_encoder = label_encoder.to(device)\n",
    "\n",
    "# Load or generate the vocabularies\n",
    "vocabularies = get_or_generate_vocabularies(\n",
    "    paths[\"FULL_DATA_PATH\"], paths[\"VOCABULARIES_DIR\"], logger)\n",
    "\n",
    "# Create datasets\n",
    "datasets = ProteinDataset.create_multiple_datasets(\n",
    "    paths_list=config['dataset_paths_list'],\n",
    "    config=config,\n",
    "    logger=logger,\n",
    "    label_tokenizer=label_tokenizer,\n",
    "    label_encoder=label_encoder,\n",
    "    vocabularies=vocabularies,\n",
    "    subset_fractions={\n",
    "        \"train\": params[\"TRAIN_SUBSET_FRACTION\"],\n",
    "        \"validation\": params[\"VALIDATION_SUBSET_FRACTION\"],\n",
    "        \"test\": params[\"TEST_SUBSET_FRACTION\"],\n",
    "    },\n",
    "    deduplicate=params[\"DEDUPLICATE\"],\n",
    ")\n",
    "\n",
    "# Seed everything so we don't go crazy\n",
    "seed_everything(params[\"SEED\"], device)\n",
    "\n",
    "# Initialize new run\n",
    "logger.info(\n",
    "    f\"################## {timestamp} RUNNING main.py ##################\")\n",
    "\n",
    "# Define label sample sizes for train, validation, and test loaders\n",
    "label_sample_sizes = {\n",
    "    \"train\": params[\"TRAIN_LABEL_SAMPLE_SIZE\"],\n",
    "    \"validation\": params[\"VALIDATION_LABEL_SAMPLE_SIZE\"],\n",
    "    \"test\": None  # No sampling for the test set\n",
    "}\n",
    "\n",
    "# Define data loaders\n",
    "loaders = create_multiple_loaders(\n",
    "    datasets,\n",
    "    params,\n",
    "    label_sample_sizes=label_sample_sizes,\n",
    "    shuffle_labels=params['SHUFFLE_LABELS'],\n",
    "    in_batch_sampling=params['IN_BATCH_SAMPLING'],\n",
    "    num_workers=params[\"NUM_WORKERS\"],\n",
    "    world_size=1,\n",
    "    rank=rank,\n",
    ")\n",
    "\n",
    "if not params[\"TRAIN_LABEL_ENCODER\"]:\n",
    "    # Move the label encoder to CPU\n",
    "    label_encoder = label_encoder.cpu()\n",
    "\n",
    "# Initialize ProteInfer\n",
    "sequence_encoder = ProteInfer.from_pretrained(\n",
    "    weights_path=paths[\"PROTEINFER_WEIGHTS_PATH\"],\n",
    "    num_labels=config[\"embed_sequences_params\"][\"PROTEINFER_NUM_LABELS\"],\n",
    "    input_channels=config[\"embed_sequences_params\"][\"INPUT_CHANNELS\"],\n",
    "    output_channels=config[\"embed_sequences_params\"][\"OUTPUT_CHANNELS\"],\n",
    "    kernel_size=config[\"embed_sequences_params\"][\"KERNEL_SIZE\"],\n",
    "    activation=torch.nn.ReLU,\n",
    "    dilation_base=config[\"embed_sequences_params\"][\"DILATION_BASE\"],\n",
    "    num_resnet_blocks=config[\"embed_sequences_params\"][\"NUM_RESNET_BLOCKS\"],\n",
    "    bottleneck_factor=config[\"embed_sequences_params\"][\"BOTTLENECK_FACTOR\"],\n",
    ")\n",
    "\n",
    "# Generate all sequence embeddings upfront, if not training the sequence encoder\n",
    "sequence_embedding_df = None\n",
    "if not params[\"TRAIN_SEQUENCE_ENCODER\"]:\n",
    "    sequence_embedding_df = get_or_generate_sequence_embeddings(\n",
    "        paths,\n",
    "        device,\n",
    "        sequence_encoder,\n",
    "        datasets,\n",
    "        params,\n",
    "        logger,\n",
    "    )\n",
    "    sequence_encoder = sequence_encoder.to('cpu')\n",
    "\n",
    "# Loop through all the datasets and set the sequence embedding df\n",
    "for dataset in datasets.values():\n",
    "    for subset in dataset:\n",
    "        if not params[\"TRAIN_SEQUENCE_ENCODER\"]:\n",
    "            subset.set_sequence_embedding_df(sequence_embedding_df)\n",
    "\n",
    "\n",
    "loaders[\"train\"][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.cuda.amp import autocast\n",
    "def tokenize_labels(text, tokenizer, max_length=1024):\n",
    "    \"\"\"\n",
    "    Tokenize a list of text strings.\n",
    "\n",
    "    Args:\n",
    "        text (list): The list of text strings.\n",
    "        tokenizer (transformers.PreTrainedTokenizer): The tokenizer.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing tokenized labels as 'input_ids' and 'attention_mask'.\n",
    "    \"\"\"\n",
    "    return tokenizer(\n",
    "        text, padding='longest', truncation=True, max_length=max_length, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_mean_hidden_states(last_hidden_states, attention_mask):\n",
    "    \"\"\"Compute the mean of the last hidden state for only the relevant tokens.\"\"\"\n",
    "    # Compute the number of relevant tokens for each sequence\n",
    "    num_relevant_tokens = attention_mask.sum(dim=1, keepdim=True)\n",
    "    # Mask the last_hidden_state tensor and compute the sum\n",
    "    sum_hidden_states = (last_hidden_states *\n",
    "                         attention_mask.unsqueeze(-1)).sum(dim=1)\n",
    "    # Compute the mean of the last hidden state\n",
    "    return sum_hidden_states / num_relevant_tokens\n",
    "\n",
    "\n",
    "def get_label_embeddings(tokenized_labels, model, batch_size_limit=1000):\n",
    "    \"\"\"\n",
    "    Get embeddings for a list of tokenized labels.\n",
    "    Assumes that tokenized_labels and model are on the same device, ideally GPU.\n",
    "    \"\"\"\n",
    "    total_labels = tokenized_labels[\"input_ids\"].shape[0]\n",
    "\n",
    "    if total_labels <= batch_size_limit:\n",
    "        with autocast():\n",
    "            last_hidden_states = model(\n",
    "                input_ids=tokenized_labels[\"input_ids\"],\n",
    "                attention_mask=tokenized_labels[\"attention_mask\"]\n",
    "            ).last_hidden_state\n",
    "        output = compute_mean_hidden_states(\n",
    "            last_hidden_states, tokenized_labels[\"attention_mask\"])\n",
    "        del last_hidden_states\n",
    "        return output\n",
    "\n",
    "    else:\n",
    "        # Convert dictionary values to tensors\n",
    "        tensors = [tokenized_labels[\"input_ids\"],\n",
    "                   tokenized_labels[\"attention_mask\"]]\n",
    "        # Create TensorDataset and DataLoader\n",
    "        dataset = TensorDataset(*tensors)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size_limit,\n",
    "                                shuffle=False, pin_memory=False, num_workers=0)\n",
    "\n",
    "        all_label_embeddings = []\n",
    "        for batch in dataloader:\n",
    "            input_ids, attention_mask = batch\n",
    "            with autocast():\n",
    "                last_hidden_states = model(\n",
    "                    input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "            mean_hidden_states = compute_mean_hidden_states(\n",
    "                last_hidden_states, attention_mask)\n",
    "            all_label_embeddings.append(mean_hidden_states)\n",
    "            del last_hidden_states, mean_hidden_states\n",
    "        # Concatenate all the label embeddings\n",
    "        return torch.cat(all_label_embeddings, dim=0)\n",
    "\n",
    "\n",
    "def generate_label_embeddings_from_text(label_annotations, label_tokenizer, label_encoder, batch_size_limit=1000):\n",
    "    \"\"\"Tokenize the labels and generate label embeddings.\"\"\"\n",
    "    tokenized_labels = tokenize_labels(label_annotations, label_tokenizer)\n",
    "\n",
    "    # Move to GPU\n",
    "    tokenized_labels[\"input_ids\"] = tokenized_labels[\"input_ids\"].to(\n",
    "        label_encoder.device)\n",
    "    tokenized_labels[\"attention_mask\"] = tokenized_labels[\"attention_mask\"].to(\n",
    "        label_encoder.device)\n",
    "\n",
    "    # Generate label embeddings\n",
    "    return get_label_embeddings(tokenized_labels, label_encoder, batch_size_limit=batch_size_limit)\n",
    "\n",
    "# Initialize label tokenizer\n",
    "label_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    params['LABEL_ENCODER_CHECKPOINT'],\n",
    ")\n",
    "\n",
    "# Initialize label encoder\n",
    "label_encoder = AutoModel.from_pretrained(\n",
    "    params['LABEL_ENCODER_CHECKPOINT'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.data import read_pickle\n",
    "annot=read_pickle('data/annotations/go_annotations_2019_07_01.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GO:0070327',\n",
       " 'The directed movement of thyroid hormone into, out of or within a cell, or between cells, by means of some agent such as a transporter or pore.')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=32000\n",
    "annot.index[i],annot.iloc[i]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22605"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0].label2int[annot.index[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8438,  0.1259,  0.2046,  ...,  0.4670, -0.1736,  0.8953]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_label_embeddings_from_text([annot.iloc[i]['label']],label_tokenizer=label_tokenizer,label_encoder=label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_iter = iter(loaders[\"train\"][0])\n",
    "data_iter = iter(datasets[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch = next(data_iter)\n",
    "loader_batch=next(loader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8445,  0.1256,  0.2044,  ...,  0.4676, -0.1743,  0.8949])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_batch['label_embeddings'][22605]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13652"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0].label2int['GO:0035639']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([datasets[\"train\"][0].label2int[i] for i in datasets[\"train\"][0].data[0][1][1:]])==torch.where(data_batch['label_multihots']==1)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GO:0035639',\n",
       " 'GO:0032553',\n",
       " 'GO:0005524',\n",
       " 'GO:0017076',\n",
       " 'GO:0005737',\n",
       " 'GO:1901265',\n",
       " 'GO:1901363',\n",
       " 'GO:0043168',\n",
       " 'GO:0044424',\n",
       " 'GO:0030554',\n",
       " 'GO:0005488',\n",
       " 'GO:0043167',\n",
       " 'GO:0042026',\n",
       " 'GO:0032559',\n",
       " 'GO:0005515',\n",
       " 'GO:0051082',\n",
       " 'GO:0032555',\n",
       " 'GO:0005575',\n",
       " 'GO:0008144',\n",
       " 'GO:0009987',\n",
       " 'GO:0097159',\n",
       " 'GO:0006457',\n",
       " 'GO:0000166',\n",
       " 'GO:0008150',\n",
       " 'GO:0036094',\n",
       " 'GO:0003674',\n",
       " 'GO:0044464',\n",
       " 'GO:0097367']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0].data[0][1][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence_onehots': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'sequence_id': 'P60545',\n",
       " 'sequence_embedding': tensor([-0.0553, -0.3441, -0.2825,  ...,  0.4497, -0.0895, -0.1504]),\n",
       " 'sequence_length': tensor(538),\n",
       " 'label_multihots': tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       " 'tokenized_labels': {'input_ids': tensor([[   2,   18,  569,  ...,    1,    1,    1],\n",
       "         [   2,   18, 1900,  ...,    1,    1,    1],\n",
       "         [   2,   18,  371,  ...,    1,    1,    1],\n",
       "         ...,\n",
       "         [   2,   18,  919,  ...,    1,    1,    1],\n",
       "         [   2,   18,  919,  ...,    1,    1,    1],\n",
       "         [   2,   18,  919,  ...,    1,    1,    1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])},\n",
       " 'label_embeddings': tensor([[-1.3426e+00,  1.9259e-01,  4.5337e-01,  ..., -6.7419e-02,\n",
       "           1.7350e-01,  8.9762e-01],\n",
       "         [-5.8517e-01,  2.5346e-03,  9.9431e-01,  ...,  7.3632e-01,\n",
       "           1.3791e+00,  1.2030e+00],\n",
       "         [-4.8449e-01, -2.6923e-01,  1.7874e-01,  ..., -3.5807e-01,\n",
       "           8.9524e-01,  8.7176e-01],\n",
       "         ...,\n",
       "         [-2.0514e-01, -1.0103e+00,  1.2279e+00,  ...,  3.6141e-01,\n",
       "          -3.4265e-01,  5.1903e-01],\n",
       "         [-8.9557e-01, -5.3069e-01,  9.3757e-01,  ..., -1.8156e-01,\n",
       "          -2.4020e-02, -9.7481e-04],\n",
       "         [-7.9217e-01, -9.6587e-01,  1.2481e+00,  ...,  4.1990e-01,\n",
       "          -3.4655e-01,  1.0383e-02]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.load('data/embeddings/frozen_BioGPT_label_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3426e+00,  1.9259e-01,  4.5337e-01,  ..., -6.7419e-02,\n",
       "          1.7350e-01,  8.9762e-01],\n",
       "        [-5.8517e-01,  2.5346e-03,  9.9431e-01,  ...,  7.3632e-01,\n",
       "          1.3791e+00,  1.2030e+00],\n",
       "        [-4.8449e-01, -2.6923e-01,  1.7874e-01,  ..., -3.5807e-01,\n",
       "          8.9524e-01,  8.7176e-01],\n",
       "        ...,\n",
       "        [-2.0514e-01, -1.0103e+00,  1.2279e+00,  ...,  3.6141e-01,\n",
       "         -3.4265e-01,  5.1903e-01],\n",
       "        [-8.9557e-01, -5.3069e-01,  9.3757e-01,  ..., -1.8156e-01,\n",
       "         -2.4020e-02, -9.7481e-04],\n",
       "        [-7.9217e-01, -9.6587e-01,  1.2481e+00,  ...,  4.1990e-01,\n",
       "         -3.4655e-01,  1.0383e-02]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3426e+00,  1.9259e-01,  4.5337e-01,  ..., -6.7419e-02,\n",
       "          1.7350e-01,  8.9762e-01],\n",
       "        [-5.8517e-01,  2.5346e-03,  9.9431e-01,  ...,  7.3632e-01,\n",
       "          1.3791e+00,  1.2030e+00],\n",
       "        [-4.8449e-01, -2.6923e-01,  1.7874e-01,  ..., -3.5807e-01,\n",
       "          8.9524e-01,  8.7176e-01],\n",
       "        ...,\n",
       "        [-2.0514e-01, -1.0103e+00,  1.2279e+00,  ...,  3.6141e-01,\n",
       "         -3.4265e-01,  5.1903e-01],\n",
       "        [-8.9557e-01, -5.3069e-01,  9.3757e-01,  ..., -1.8156e-01,\n",
       "         -2.4020e-02, -9.7481e-04],\n",
       "        [-7.9217e-01, -9.6587e-01,  1.2481e+00,  ...,  4.1990e-01,\n",
       "         -3.4655e-01,  1.0383e-02]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['label_embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_e = a['sequence_embeddings']\n",
    "L_e = a['label_embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:15<00:00,  4.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "joint = []\n",
    "for i in tqdm(P_e):\n",
    "    for j in L_e:\n",
    "        joint.append(torch.concat([i,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'repeat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/samirchar/ProteinFunctions/notebooks/debugging copy.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbastion_tunnel/home/samirchar/ProteinFunctions/notebooks/debugging%20copy.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49mrepeat(\u001b[39m10\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'repeat'"
     ]
    }
   ],
   "source": [
    "torch.repe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 5448.56it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "joint = []\n",
    "joint_matrix = []\n",
    "for i in tqdm(range(10)):\n",
    "    joint_rows=[]\n",
    "    for j in range(11,15):\n",
    "        i_ = torch.tensor([i]*5)\n",
    "        j_ = torch.tensor([j]*7)\n",
    "        concat = torch.concat([i_,j_])\n",
    "        joint.append(concat)\n",
    "        joint_rows.append(concat)\n",
    "    joint_rows = torch.stack(joint_rows)\n",
    "    joint_matrix.append(joint_rows)\n",
    "\n",
    "#joint = torch.stack(joint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 77,  84,  91,  98],\n",
       "        [ 82,  89,  96, 103],\n",
       "        [ 87,  94, 101, 108],\n",
       "        [ 92,  99, 106, 113],\n",
       "        [ 97, 104, 111, 118],\n",
       "        [102, 109, 116, 123],\n",
       "        [107, 114, 121, 128],\n",
       "        [112, 119, 126, 133],\n",
       "        [117, 124, 131, 138],\n",
       "        [122, 129, 136, 143]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(joint_matrix).sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(103)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(joint_matrix)[1][3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 77,  84,  91,  98],\n",
       "        [ 82,  89,  96, 103],\n",
       "        [ 87,  94, 101, 108],\n",
       "        [ 92,  99, 106, 113],\n",
       "        [ 97, 104, 111, 118],\n",
       "        [102, 109, 116, 123],\n",
       "        [107, 114, 121, 128],\n",
       "        [112, 119, 126, 133],\n",
       "        [117, 124, 131, 138],\n",
       "        [122, 129, 136, 143]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint.sum(axis=1).reshape(10,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 12])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-80840.0156)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint.sum(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sequences = P_e.shape[0]\n",
    "num_labels = L_e.shape[0]\n",
    "sequence_embedding_dim = P_e.shape[1]\n",
    "label_embedding_dim = L_e.shape[1]\n",
    "\n",
    "# Use broadcasting so we don't have to expand the tensor dimensions\n",
    "joint_embeddings = torch.cat([\n",
    "    P_e[:, None, :].expand(\n",
    "        num_sequences, num_labels, sequence_embedding_dim),\n",
    "    L_e[None, :, :].expand(\n",
    "        num_sequences, num_labels, label_embedding_dim)\n",
    "], dim=2).reshape(-1, sequence_embedding_dim + label_embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-80840.0156)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_embeddings.sum(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 1],\n",
       "        [0, 1, 1],\n",
       "        [1, 1, 0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,0,1,0,1,1,1,1,0]).reshape(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Train and/or Test the ProTCL model.\")\n",
    "parser.add_argument(\"--train-path-name\", type=str, default=None,\n",
    "                    help=\"Specify the desired train path name to train the model using names from config file. If not provided, model will not be trained. If provided, must also provide --val-path.\")\n",
    "\n",
    "parser.add_argument(\"--validation-path-name\", type=str, default=None,\n",
    "                    help=\"Specify the desired val path name to validate the model during training using names from config file. If not provided, model will not be trained. If provided, must also provide --train-path.\")\n",
    "\n",
    "parser.add_argument(\"--full-path-name\", type=str, default=None,\n",
    "                    help=\"Specify the desired full path name to define the vocabularies. Defaults to the full path name in the config file.\")\n",
    "\n",
    "parser.add_argument(\"--test-paths-names\", nargs=\"+\", type=str, default=None,\n",
    "                    help=\"Specify all the desired test paths names to test the model using names from config file to test. If not provided, model will not be tested.\")\n",
    "\n",
    "parser.add_argument(\"--use-wandb\", action=\"store_true\", default=False,\n",
    "                    help=\"Use Weights & Biases for logging. Default is False.\")\n",
    "\n",
    "parser.add_argument(\"--load-model\", type=str, default=None,\n",
    "                    help=\"(Relative) path to the model to be loaded. If not provided, a new model will be initialized.\")\n",
    "\n",
    "parser.add_argument('--from-checkpoint', action=\"store_true\", default=False,\n",
    "                    help=\"Continue training from a previous model checkpoint (including optimizer state and epoch). Default is False.\")\n",
    "\n",
    "parser.add_argument(\"--name\", type=str, default=\"ProTCL\",\n",
    "                    help=\"Name of the W&B run. If not provided, a name will be generated.\")\n",
    "\n",
    "parser.add_argument(\"--config\", type=str, default=\"configs/base_config.yaml\",\n",
    "                    help=\"(Relative) path to the configuration file.\")\n",
    "\n",
    "parser.add_argument(\"--amlt\", action=\"store_true\", default=False,\n",
    "                    help=\"Run job on Amulet. Default is False.\")\n",
    "\n",
    "parser.add_argument(\"--override\", nargs=\"*\",\n",
    "                    help=\"Override config parameters in key-value pairs.\")\n",
    "\n",
    "parser.add_argument(\"--save-prediction-results\", action=\"store_true\", default=False,\n",
    "                    help=\"Save predictions and ground truth dataframe for validation and/or test\")\n",
    "\n",
    "parser.add_argument('-n', '--nodes', default=1, type=int,\n",
    "                    metavar='N', help='Number of nodes (default: 1)')\n",
    "\n",
    "parser.add_argument('-g', '--gpus', default=1, type=int,\n",
    "                    help='Number of gpus per node (default: 1)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein_functions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
