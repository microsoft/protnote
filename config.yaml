---
# Parameters for model training
params:
  LEARNING_RATE: 0.0003
  TEMPERATURE: 0.1
  PROTEIN_EMBEDDING_DIM: 1100
  LABEL_EMBEDDING_DIM: 768
  LATENT_EMBEDDING_DIM: 934
  NUM_EPOCHS: 10
  TRAIN_BATCH_SIZE: 1024
  VALIDATION_BATCH_SIZE: 1024
  TEST_BATCH_SIZE: 1024
  VALIDATION_FREQUENCY: 50
  DECISION_TH: 0.88
  NUM_WORKERS: 3
  METRICS_AVERAGE: micro
  SEED: 42

# Paths to data, vocabularies, embeddings, and models
relative_paths:
  # Data paths
  TRAIN_DATA_PATH: data/swissprot/proteinfer_splits/random/train_GO.fasta
  VAL_DATA_PATH: data/swissprot/proteinfer_splits/random/dev_GO.fasta
  TEST_DATA_PATH: data/swissprot/proteinfer_splits/random/test_GO.fasta
  FULL_DATA_PATH: data/swissprot/proteinfer_splits/random/full_GO.fasta

  # Vocabulary paths
  VOCABULARIES_DIR: data/vocabularies
  AMINO_ACID_VOCAB_PATH: data/vocabularies/amino_acid_vocab.json
  GO_LABEL_VOCAB_PATH: data/vocabularies/GO_label_vocab.json
  SEQUENCE_ID_VOCAB_PATH: data/vocabularies/sequence_id_vocab.json

  # Embeddings paths (if using frozen pre-trained models)
  EMBEDDING_DIR: data/embeddings
  LABEL_EMBEDDING_PATH: data/embeddings/frozen_PubMedBERT_label_embeddings.pkl
  SEQUENCE_EMBEDDING_PATH: data/embeddings/frozen_proteinfer_sequence_embeddings.pkl

  # Map from alphanumeric sequence IDs to integer sequence IDs
  SEQUENCE_ID_MAP_PATH: data/embeddings/sequence_id_map.pkl

  # Where to save the model
  OUTPUT_MODEL_DIR: models/ProTCL

  # Where to load the model from, if using an existing model
  STATE_DICT_PATH: null
  PARENTHOOD_LIB_PATH: data/proteinfer_results/
  PROTEINFER_WEIGHTS_PATH: 'models/proteinfer/GO_model_weights.pkl'

#Params for protein encoder model (e.g. ProteInfer)
embed_sequences_params:
  NUM_LABELS: 32102
  INPUT_CHANNELS: 20
  OUTPUT_CHANNELS: 1100
  KERNEL_SIZE: 9
  DILATION_BASE: 3
  NUM_RESNET_BLOCKS: 5
  BOTTLENECK_FACTOR: 0.5